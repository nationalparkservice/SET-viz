---
title: "SET Visualizer"
output:
  flexdashboard::flex_dashboard:
    theme: yeti
    orientation: columns
runtime: shiny
---

```{r global, include=FALSE}

### FIX
# Heat plot legend should not update until recalculate thresholds button is pressed
# Speed up action when recalculate thresholds
# Quantile doesn't work for heat plot
# Change per year--really it depends on season, so instead of this show some indication of season and then have a warning sign that the time btwn events is not necessarily approx annual and that hover text will show # of days since last reading and that season of survey may influence pin height. Instead of change per year, the hover text should include # of days since last reading 
# Seasonal patterns--check what y-axis is, I think it's not change-per-yr right?
# Can i get x-axis label on each heat plot matrix?

### PICK UP FROM HERE
# Records Export Page 
# >> side panel allows user to choose which columns to view (and export). 
# I think I should allow user to save the QAQC_COMMENTS data in .RDS for later processing.


### NOTES
# Converted all tibbles to data frames to get rid of phantom column name errors

### QUESTIONS
# pin_position --is that column name correct?
# check if I identified the correct cols to be factor, integer, date formats
# Removing records with NA in any of these columns (station_name, visit_date, SET_direction_azimuth, pin_position, pin_height_mm)--any reason to keep those in? Can provide an output of which records were excluded, or just a summary of counts
# When calculating diff, only use 'Standard observation'?
# How to deal with some pins having base pin height and others not?
# On heat map page, do you want to be able to select a park or use previously selected park and filters?
# Will a station always have 4 directions and 9 pins/dxn? (otherwise need to have flexible heat map sizing)

### TO DO
# Make sure x-axis range consistent across all stations in site

### NAMING RULES
# Functions: FuncTest(dat1_there, dat2_here)
# Action buttons: button_PushMe
# User inputs: sel_SelectMe
# Lists, data frames, vectors, variables...: station_files_list, station_df, station_vec, here_is_a_variable
# Data frame cols: df$ColThisOne, df$ColThatOne
# List elements: list$ElementOne, list$ElementTwo
# Reactive elements: rv$ThisOne, rv$ThatOne
# Temporary variables: temp_this_df
# Well panel id's: wp_FilterParkSite

rm(list=ls())

### Load libraries -----
# Will automatically install any libraries it can't find
packages <- c("flexdashboard", 
              "shiny", 
              "knitr",  
              "scales",
              "leaflet", 
              "RgoogleMaps", # for mapzoom
              "plotly", 
              "tidyverse", 
              "plyr", 
              "readr",
              "magrittr", 
              "leaflet.extras", 
              "lubridate", 
              "here", 
              "httr", # use web services
              "rgdal", # to use readOGR
              "sp", # transform projections
              "purrr", # for applying functions to dplyr groups
              "dataMaid", # for data checks
              "shinyFiles", # for user to save files in specified location
              "RColorBrewer", # to display brewer palettes
              "shinyjs", # for easy functions that use JavaScript
              "stringr", # to detect text snippets
              "tmaptools", # for flexible color mapping
              "DT", # for interactive tables
              "zoo", # for year-month and carry-forward NA's for lag
              "cowplot", # to get legends from plots
              "gridExtra", # for arranging plots and adding plot annotations (ggplotly can't do captions or subtitles)
              "RgoogleMaps", # for MaxZoom & MinZoom
              "leaflet.minicharts") # for pie charts in leaflet maps

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE, repos = "http://cran.us.r-project.org")
    library(x, character.only = TRUE)
  }
})

options(shiny.maxRequestSize = 20*1024^2, 
        timeout = 300,
        stringsAsFactors = FALSE,
        DT.options = list(
          hover = TRUE,
          scrollX = TRUE,
          scrollY = TRUE,
          autoWidth = FALSE),
        # Header width doesn't match body width when this is set to TRUE. To fix, would need to include code to recalculate widths only after a tab is visible. If setting column widths, need to set autoWidth to TRUE
        dplyr.summarise.inform = FALSE
)

# dataMaid helper function that needs to be in global - rotate plot, wrap and truncate long labels
vertLabPlot <- function(x, xlab, main) { 
  qplot(x = stringr::str_wrap(substring(x, 0, 42), 15), xlab = xlab, main = main) +
    coord_flip()
  }

# dataMaid helper function that needs to be in global - visualFunction for character, factor, labelled and logical variables
vertLabStandardVisual  <- function(v, vnam, doEval = TRUE) {
  v <- dataMaid:::escapeRStyle(na.omit(v))
  thisCall <- call("vertLabPlot", x=v, xlab="", main=vnam)
  if (doEval) {
    return(eval(thisCall))
  } else return(deparse(thisCall))
}
```

```{r startup}
rv <- reactiveValues(DataSET = NULL, DataStation = NULL, UnitPoly = NULL, SubDataSET = NULL, SubDataSETRaw = NULL, SubDataSummary = NULL, SubDataDateSummary = NULL, PlotData = NULL, ShowDM = FALSE, ThreshDataSET = NULL, ThreshCounts = NULL, PickList = NULL, ThreshHeatPlots = NULL, SeasonalPlots = NULL, MapDat = NULL, DataSET_NERRs = NULL)

cbp1 <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#0072B2", "#D55E00", "#999999", "#F0E442", "#000000", "chocolate4", "purple4", "chartreuse", "lightpink", "honeydew2") # Colorblind-friendly palette that will be used throughout
```

```{r css}

# This allows renderTables to scroll when overflow
tags$style(".chart-wrapper {
  overflow-x:scroll;
  overflow-y:scroll;
}")

tags$style("table.dataTable tbody th, table.dataTable tbody td input.form-control {
    padding: 2px 5px; 
}") # reduce padding in data tables
```

```{r functions}

### FUNCTIONS ----
FuncAllNoneButtons <- function(cond, name_all, name_none) {
  # Function to create 'Select All' and 'Select None' action buttons
  #
  # Args:
  #   cond:  The input ID that needs to be defined for buttons to show (enter as input.XXX rather than as input$XXX)
  #   name_all:  ID to assign to 'Select All' button
  #   name_none:  ID to assign to 'Select None' button
  #
  conditionalPanel(
    condition = paste0("typeof ", cond, " !== 'undefined'"),
    actionButton(name_all, "Select All", style="color:black; display:inline-block; border:1px; padding:4px 12px;"),
    actionButton(name_none, "Select None", style="color:black; display:inline-block; border:1px; padding:4px 12px;")
  )
}

FuncBreakDates <- function(dat) {
  # Function to break dates into date categories
  #
  # Args:
  #   dat:  A SET data frame with the raw data. One column needs to be visit_date, with format mm/dd/yyyy
  #
  # Returns:
  #   A data frame with additional columns classifying survey date by week, month, year
  #
  dat %<>% 
    dplyr::mutate(
      visit_yr = lubridate::year(visit_date), # for annual summaries
      visit_month = factor(lubridate::month(visit_date), levels = 1:12),
      visit_week = factor(lubridate::week(visit_date), levels = 1:53)
    )
  # dat$visit_yr <- factor(dat$visit_yr, levels = min(dat$visit_yr, na.rm = TRUE):max(dat$visit_yr, na.rm = TRUE)) # make sure any missing years are still shown in plots
  return(dat)
}

FuncParkBoundaries <- function(park_vec) {
  # Function to get park unit boundaries from IRMA
  #
  # Args:
  #   park_vec: Vector of 4-letter park codes for which boundaries should be obtained
  #
  # Returns:
  #   A data frame with additional columns classifying survey date by week, month, year
  
     unitBoundaryURL <- paste0("https://services1.arcgis.com/fBc8EJBxQRMcHlei/ArcGIS/rest/services/IMD_Units_Generic_areas_of_analysis_(AOAs)_-_IMD_BND_ALL_UNITS_AOA_nad_py_view/FeatureServer/1/query?where=UNITCODE+%3D+%27, park_vec, %27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=") # save output as WGS84

     if(httr::http_status(GET(unitBoundaryURL))$category!="Success") { # if not a valid service call or if the web service is down, abort
       showModal(
         urlModal(unitBoundaryURL, title = "Data Retrieval Error", subtitle = paste0("Error retrieving park_name unit boundary data from IRMA. The message from the web service is: `", http_status(GET(unitBoundaryURL))$message, "`.\n\nTo confirm this is a problem with the web service (and not the dashboard), enter the above URL in a browser and see if data successfully downloads. If an error results, email IRMA support (irma@nps.gov) for assistance."))
       )
       }

     shiny::req(httr::http_status(GET(unitBoundaryURL))$category=="Success")

    tempUnitOutput <- "tempUnit.geojson"
    download.file(unitBoundaryURL, tempUnitOutput) # readOGR geoJSON driver needs dsn to be a local file, so download the file first, then read it

    imported_dat <- tryCatch(rgdal::readOGR(dsn = tempUnitOutput, dropNULLGeometries = FALSE), error=function(e) print("Error retrieving data")) # return error message if problems still arise with downloading from web services
    if(class(imported_dat)!="SpatialPolygonsDataFrame") {
       showModal(
         urlModal(unitBoundaryURL, title = "Data Retrieval Error", subtitle = paste0("Could not successfully retrieve park_name unit boundary data from IRMA. To see if this is a problem with the web service (and not the dashboard), enter the above URL in a browser and see if data successfully downloads with boundary information in geojson format. If necessary, email IRMA support (irma@nps.gov) for assistance."))
       )
    }

    shiny::req(class(imported_dat)=="SpatialPolygonsDataFrame")
    imported_dat <- sp::spTransform(imported_dat, sp::CRS("+proj=longlat +datum=WGS84")) # convert to WGS84

    rv$UnitPoly <- imported_dat
    rm(imported_dat)
    unlink("tempUnit.geojson")
}

FuncCalcChange <- function(dat) {
  # Function to calculate change per year for pin height
  #
  # Args:
  #   dat:  A SET data frame output from FuncBreakDates
  #
  # Returns:
  #   A data frame with an additional column calculating change in pin height per year. When prior survey is NA, will calculate pin difference and date difference from the last non-NA pin height.
  #
   lg <- function(x)c(NA, x[1:(length(x)-1)]) # lag function
  dat$next_visit_date <- c(dat$visit_date[-1], NA) # need this to calculate DIffDays correctly (skipping the NA dates, but still need visit_date to order the readings correctly)
  dat$temp_visit_date[is.na(dat$pin_height_mm)] <- NA
  temp_dat <- dat %>%
    dplyr::group_by(park_name, park_code, site_name, station_name, SET_direction_azimuth, pin_position) %>%
    dplyr::arrange(visit_date) %>%
    dplyr::mutate(
      # diff_height_mm = pin_height_mm - zoo::na.locf(dplyr::lag(pin_height_mm, order_by = visit_date), na.rm = FALSE), # when previous value is NA, it finds the difference to the most recent non-NA
      # diff_days = temp_visit_date - zoo::na.locf(dplyr::lag(temp_visit_date, order_by = visit_date), na.rm = FALSE), # when previous value is NA, it finds the difference to the most recent non-NA
      diff_height_mm = pin_height_mm - dplyr::lag(pin_height_mm),
      diff_days = temp_visit_date - dplyr::lag(temp_visit_date),
      change_per_year_mm = round((diff_height_mm/as.double(diff_days, units = "days"))*365, 1)
    ) %>%
    dplyr::select(-temp_visit_date) %>%
    dplyr::ungroup()
  
  return(temp_dat)
}
  
FuncUpdateCheckCols = function(input_edit, output_table, proxyDT) {
  # Function to update the Check columns of rv$DataSET
  #
  # Args:
  #   input_edit: The reactive input for edited DT cell, e.g., input$raw_table_cell_edit. Must begin with 'input$' and end with '_cell_edit'
  #   proxyDT:  The name of the proxy data table, e.g., raw_proxyDT
  #
  # Returns:
  #   Updates rv$DataSET
  #
  info = input_edit
  i = info$row
  j = info$col
  v = info$value

  ID_change <- rv$SubDataSETRaw$record_ID[i]
  rv$DataSET[rv$DataSET$record_ID==ID_change, "QAQC_COMMENTS"] <<- DT::coerceValue(v, rv$DataSET[rv$DataSET$record_ID==ID_change, "QAQC_COMMENTS"]) # update in the raw

}

FuncCalcQuant <- function(dat, sel_unit) {
  # Function to classify change_per_year_mm by user-specified groups and quantiles
  #
  # Args:
  #   dat:  A filtered SET data frame for the selected site
  #   sel_unit:  Metric to calculate threshold categories on
  #
  # Returns:
  #   A data frame with an additional columns classifying change_per_year_mm relative to specified quantiles per group
  #
  dat <- droplevels(dat)
  names(dat)[names(dat) == sel_unit] <- "unit"
  dat %<>% dplyr::mutate(
    GroupingVar = switch(input$sel_QuantileGroup,
                         "site" = site_name,
                         "station" = station_name)) 
  quant_list <- dat %>%
    dplyr::group_by(GroupingVar) %>%
  group_map(~ quantile(.x$unit, probs = c(input$sel_QuantileLower, input$sel_QuantileUpper), na.rm = TRUE))
  quant_df <- data.frame(do.call("rbind", quant_list))
  names(quant_df) <- c("lower_cutoff", "upper_cutoff")
  quant_df$GroupingVar <- levels(dat$GroupingVar)
  
  dat2 <- dat %>%
    dplyr::left_join(quant_df, by = "GroupingVar")
  dat2$level <- ifelse(
      dat2$unit < dat2$lower_cutoff, "below", ifelse(
      dat2$unit > dat2$upper_cutoff, "above", "between(inclusive)"))
  dat2$GroupingVar <- NULL
  dat2$level <- factor(dat2$level, levels = c("below", "between(inclusive)", "above"))
  names(dat)[names(dat) == "unit"] <- sel_unit
  return(dat2)
  }

FuncCalcThresh <- function(dat, sel_unit) {
  # Function to classify change_per_year_mm by user-specified numeric thresholds
  #
  # Args:
  #   dat:  A filtered SET data frame for the specified site
  #   sel_unit:  Metric to calculate threshold categories on
  #
  # Returns:
  #   A data frame with an additional column classifying change_per_year_mm relative to specified thresholds
  #
    # saveRDS(isolate(reactiveValuesToList(input)), paste0("temp_input.RDS"))
  # saveRDS(isolate(reactiveValuesToList(rv)), paste0("temp_rv.RDS"))
  dat <- droplevels(dat)
  names(dat)[names(dat) == sel_unit] <- "unit"
  dat2 <- dat
  dat2$lower_cutoff <- input$sel_ThresholdLower
  dat2$upper_cutoff <- input$sel_ThresholdUpper
  dat2$level <- ifelse(
      dat2$unit < dat2$lower_cutoff, "below", ifelse(
      dat2$unit > dat2$upper_cutoff, "above", "between(inclusive)"))
  
  dat2$level <- factor(dat2$level, levels = c("below", "between(inclusive)", "above"))
  names(dat2)[names(dat2) == "unit"] <- sel_unit
  return(dat2)
}
  
FuncPlotlyScatter <- function(dat, x_nam = "Wk", trans_y = "identity", add_loess = TRUE, rotate_x = FALSE) {
  # Function to generate scatterplot of data
  #
  # Args:
  #   dat:  A data frame with the raw data
  #   x_nam: Column name for x-axis variable
  #   trans_y: Transformation to apply to y axis
  #   add_loess:  Add loess smooth? (will be biased by censored data)
  #   rotate_x: should x-axis labels be rotated?
  #
  # Returns:
  #   List of scatterplot
  # 
  
  shiny::req(sum(!is.na(dat$pin_height_mm)) > 0) # make sure there are data
  
  if(x_nam == "visit_date") {
    xaxes_min = min(dat$visit_date, na.rm = TRUE)
    xaxes_max = max(dat$visit_date, na.rm = TRUE)
  }
  
  yaxes_min = min(dat$pin_height_mm, na.rm = TRUE)
  yaxes_max = max(dat$pin_height_mm, na.rm = TRUE)
  
  # Create the plot(s)
    
    p_points <- ggplot(data = dat, aes(x = visit_week, y = pin_height_mm, text = paste0("Site: ", site_name, "<br>Station: ", station_name, "<br>Visit Date: ", visit_date, "<br>X-value: ", visit_week, "<br>Y-value: ", pin_height_mm))) +
      geom_jitter(aes(fill = visit_yr, color = visit_yr), size = 2, alpha = 0.5, show.legend = c(fill = TRUE, color = FALSE, shape = FALSE))
  
    # Create a pretty x-axis
    if(x_nam == "visit_date") {
      p1_points <- p_points + scale_x_date(date_breaks = "1 year", date_labels = "%Y", limits = c(xaxes_min, xaxes_max))
    } else {
      p1_points <- p_points + scale_x_discrete(breaks = levels(dat$visit_week), drop = FALSE)
    }
    
    # If adding loess smooth...
    # if(add_loess) {
      p1_points <- p1_points + geom_smooth(data = dat, aes(x = visit_week, y = pin_height_mm), method = "loess", size = 0.5, alpha = 0.2, show.legend = FALSE)
      # }
    
    # Final formatting of plots
    p1_points <- p1_points +
      scale_y_continuous(trans = trans_y, labels = function(x) as.character(round(x,1)), breaks = pretty_breaks(), limits = c(yaxes_min, yaxes_max)) + # alternatively, can use 'coord_cartesian(ylim = c(axes_min, axes_max))' to zoom in to the limits rather than "cutting off" the limits, as setting limits within scale_y_continuous() would do 
      theme_bw(base_size = 11) +
      {if(rotate_x) {theme(axis.text.x = element_text(angle = 60, hjust = 1))}} +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.position = "top",
            legend.text = element_text(size = 16),
            legend.title = element_text(size = 16)) +
      facet_wrap(. ~ station_name, drop = TRUE, ncol = 1) # add the name as facet label
    out_plotly <- ggplotly(
      p1_points,
      height = 400*length(unique(dat$station_name))) # THIS IS NOT WORKING--CAN'T SCROLL DOWN
    
  return(out_plotly)
}

FuncPlotlyHeatPlot <- function(dat, discrete_cols = c("#ffd700", "#add8e6", "#ffa500"), discrete_levels = c("below", "between(inclusive)", "above")) {
  # Function to create plotly heatmaps of change_per_year_mm, organized station. Using plot_ly because ggplotly is too slow for interactive heat plots b/c it doesn't recognize the input as a heatmap and creates a scatterplot where each rectangle is drawn separately with all the necessary attributes. 
  #
  # Args:
  #   dat:  A filtered SET data frame with quantile/threshold classification for a single site
  #   discrete_cols: For discrete fill, the vector of colors
  #   discrete_levels: For discrete fill, the levels corresponding with colors
  #   
  # Returns:
  #   GGplot heat map
  #
  dat2 <- dat %>%
    ungroup() %>%
    dplyr::select(record_ID, site_name, station_name, SET_direction_azimuth, pin_position, visit_date, pin_height_mm, observation_type, pin_position, diff_height_mm, diff_days, change_per_year_mm, lower_cutoff, upper_cutoff, level) %>%
    dplyr::arrange(record_ID) %>%
    dplyr::mutate(hover_label = paste0("Record ID: ", record_ID, "<br>Visit Date: ", visit_date, "<br>Observation Type: ", observation_type, "<br>Pin Position: ", pin_position, "<br>Pin Height (mm): ", pin_height_mm, "<br>Height Diff (mm): ", diff_height_mm, "<br>Days Diff: ", diff_days, "<br>Upper Cutoff: ", upper_cutoff, "<br>Lower Cutoff", lower_cutoff, "<br>Change Per Yr (mm): ", change_per_year_mm, "<br>LEVEL: ", level)) %>%
    droplevels()
  
  # Calculate total and relative heights
  temp_distinct <- dat2 %>% 
    dplyr::select(station_name, SET_direction_azimuth, pin_position) %>%
    distinct()
  total_page_ht <- 30*nrow(temp_distinct)
  rel_hts <- (temp_distinct %>% dplyr::count(station_name) %>% pull(n))/nrow(temp_distinct)
  
  heat_station_list <- vector("list", length = length(unique(dat2$station_name))) # each list element is a station
  
 heat_station_list <- lapply(sort(unique(dat2$station_name)), function(i) {
    
    # Data for this station
    subdat <- dplyr::filter(dat2, station_name == i) %>%
      droplevels()
    
    # Pipe directions for this station
    pipe_dxn_list <- vector("list", length = length(unique(subdat$SET_direction_azimuth)))
    pipe_dxn_list <- lapply(sort(unique(subdat$SET_direction_azimuth)), function(j) { # subplot the pipe directions for a station
      subdat_pipe <- dplyr::filter(subdat, SET_direction_azimuth == j)
  
    # create number matrix to put values in the heatmap cells
    template <- subdat_pipe %>%
      dplyr::select(pin_position, visit_date) %>%
      expand(pin_position, visit_date) %>%
      left_join(subdat_pipe[c("SET_direction_azimuth", "pin_position", "visit_date", "change_per_year_mm", "diff_height_mm", "hover_label", "level")], by = c("pin_position", "visit_date")) %>%
      dplyr::arrange(visit_date, pin_position)
    txt <- matrix(pull(template, input$sel_CalcUnit), nrow=length(unique(template$pin_position)))
    txt[is.na(txt)] <- " " # convert NA to blank, otherwise it will show as "new text"

        
        # Create discrete color scale
  use_cols <- discrete_cols[which(discrete_levels %in% unique(na.omit(template$level)))]
  temp_seq <- seq(0,1, length.out = length(use_cols)+1)
  rep_seq <- rep(temp_seq[c(-1, -length(temp_seq))], each = 2)
  z = c(temp_seq[1], rep_seq, temp_seq[length(temp_seq)])
  color_scale <- data.frame(z=z,col=rep(use_cols, each = 2)) # the default color for NA is white
  
    plot_ly(
      data = template, 
      source = "heat_plot",
      text = text,
      width = 52*length(unique(template$visit_date)), 
      height = total_page_ht, # can't specify heights in subplot, need to set it at this plot_ly level
      showscale = FALSE) %>%
      plotly::add_heatmap(
        x = ~as.factor(visit_date),
        y = ~as.integer(pin_position),
        text = ~hover_label, # hover information
        hoverinfo ="text",
        z = ~as.numeric(factor(template$level, ordered = T, levels = discrete_levels)), # assign discrete colors to the cells
        colorscale = color_scale, 
        xgap = 0.5, # spacing between heatmap cells
        ygap = 0.5
        ) %>% 
      layout(
        hoverlabel = list(align = "left"),
        xaxis = list( # x-axis
          title = "Survey Date",
          tickangle = 270,
          titlefont=list(size=16, family = "Arial")),
        yaxis = list( # y-axis
          autorange = "reversed",
          dtick = 1)
        ) %>%
      add_annotations( 
        x = template$visit_date,
        y = as.integer(template$pin_position),
        align = "center",
        text = txt, # add the values in the cells 
        showarrow = FALSE) %>%
      add_annotations( # Pipe Direction subtitle
        text = paste0("Pipe Direction ", unique(template$SET_direction_azimuth)),
        xref = "paper",
        yref = "paper",
        x = 0.5,
        y = 1.02,
        xanchor = "center",
        yanchor = "bottom", # y anchor uses 'middle', x anchor uses 'center'
        showarrow = FALSE,
        font=list(size=16, family = "Arial")
        )
    })
    
    plotly::subplot(
        pipe_dxn_list,
        nrows = length(pipe_dxn_list),
        shareX = TRUE,
        shareY = FALSE,
        titleX = TRUE,
        titleY = FALSE
        ) %>%
        add_annotations( # shared y-axis title
          x = -0.05,
          y = 0.55,
          text = "Pin Position",
          showarrow = F, 
          xref="paper",
          yref="paper",
          xanchor="right",
          yanchor="middle", # y anchor uses 'middle', x anchor uses 'center'
          textangle=-90,
          font=list(size=16, family = "Arial")) %>%
      add_annotations( # Station name as title
        x = 0.01,
        y = 1.02,
        text = paste0("STATION ", i), 
        showarrow = F, 
        xref="paper",
        yref="paper",
        xanchor="left",
        yanchor="bottom",
        font=list(size=20, family = "Arial")
        ) %>%
      layout(
          margin = list(
          t=50,
          b=15,
          l= 80,
          r=40)
        )
 }) 
 
 final_heat_plotly <- # put the station plots together
   plotly::subplot(
     heat_station_list,
     nrows = length(heat_station_list),
     shareX = FALSE,
     shareY = FALSE,
     titleX = TRUE,
     titleY = FALSE,
     heights = rel_hts,
     which_layout = 1)
 
  return(final_heat_plotly)
}

FuncPlotlyPieMatrix <- function(dat, discrete_cols = c("#ffd700", "#add8e6", "#ffa500"), discrete_levels = c("below", "between(inclusive)", "above")) {
  # Function to create plotly pie chart matrix of change_per_year_mm, organized by user-selected grouping. 
  #
  # Args:
  #   dat:  A filtered SET data frame with quantile/threshold classification for a single site
  #   discrete_cols: For discrete fill, the vector of colors
  #   discrete_levels: For discrete fill, the levels corresponding with colors
  #   
  # Returns:
  #   Page of plotly pie charts
  #
  
  fig <- plot_ly()
  
  for(s in 1:length(unique(dat$station_name))) {
    station <- sort(unique(dat$station_name))[s]
    for(d in 2:length(unique(dat$visit_date))) { # first date is always NA's for change in pin height
      survey_date <- sort(unique(dat$visit_date))[d]
      fig <- fig %>% 
        
        add_pie(data = dplyr::filter(dat, station_name == station & visit_date == survey_date),
                labels = ~level, 
                values = ~N,
                textposition = 'inside',
                textinfo = 'label+percent',
                insidetextfont = list(color = '#FFFFFF'),
                hoverinfo = 'text',
                text = ~hover_label,
                marker = list(colors = discrete_cols, line = list(color = '#FFFFFF', width = 1)),
                domain = list(row = s-1, column = d-1))
      }
    }
  
  fig <- fig %>% layout(
    title = "Pie Charts with Subplots", 
    showlegend = FALSE,
    grid=list(
      rows=length(unique(dat$station_name)),
      columns=length(unique(dat$visit_date))),
    xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    autosize = FALSE,
    width = 80 * length(unique(dat$visit_date)), # 80
    height = 2 * length(unique(dat$station_name)) #4
    )
  
  return(fig)
}

FuncOrderCheck <- function(import = TRUE, examine = TRUE, plot = TRUE) {
  # Function to check if data have been imported, filtered, and plot data summarized

  if(import == TRUE) {
    shiny::validate(
      need(!is.null(rv$DataSET), message = "No data available. Please first import SET data."))
  }
  
  if(examine == TRUE) {
    shiny::req(!is.null(rv$DataSET))
    shiny::validate(
      need(!is.null(rv$SubDataSET), message = "Please first use the 'Examine Data' tab to choose a subset of data to examine."))
    shiny::validate(
      need(!is.null(rv$SubDataSummary), message = "Please first use the 'Examine Data' tab to choose a subset of data to examine."))
  }
  
  if(plot == TRUE) {
    shiny::req(!is.null(rv$SubDataSET))
    shiny::validate(
      need(!is.null(rv$ThreshDataSET), message = "Please first enter thresholds criteria for the heat plots, then click the green 'Recalculate Thresholds' button"))
    shiny::validate(
      need(!is.null(rv$ThreshHeatPlots), message = "Please first enter thresholds criteria for the heat plots, then click the green 'Recalculate Thresholds' button"))
  }
}

FuncFormatSET_NERRs <- function(dat) {
  temp_NERRs <- dat %>%
    dplyr::filter(park_code %in% input$sel_ExportParks) %>%
    dplyr::mutate(
      reserve = park_code,
      set_id = paste0(station_name, "_Pipe", SET_direction_azimuth),
      year = lubridate::year(visit_date),
      month = lubridate::month(visit_date),
      day = lubridate::day(visit_date),
      arm_position = SET_direction_azimuth,
      arm_qaqc_code = NA,
      pin_number = paste0("pin_", pin_position),
      height_mm = pin_height_mm,
      qaqc_code = NA) %>%
    dplyr::select(reserve, set_id, year, month, day, arm_position, arm_qaqc_code, pin_number, height_mm, qaqc_code)
  return(temp_NERRs)
}
  
```

```{r action_buttons}

# Generic action to cancel modal ----
observeEvent(eventExpr = input$button_CancelModal, {
  removeModal()
  })

# (Home) Import and format data via SQL database download ----
observeEvent(eventExpr = input$button_ImportSQL, {
  # Still need to work through the logistics of wiring this up. Based on what I know so far this requires the user to
  # have database permissions, the computer where the script is running to have a named ODBC connection, and some sort of
  # selection of at least network (or you'd get data for all 5 networks).
    { showModal(modalDialog(
      title = "Future Feature!",
      "Direct import of the data from the SQL database is a new feature that is under development!"))
    }
  }
)


# (Home) Import and format data from CSV ----
observeEvent(eventExpr = input$button_ImportCSV, {
  if(!dir.exists(file.path(here::here(), "Data_in"))) {
    showModal(modalDialog(
      title = "No 'Data_in' subfolder",
      "Could not find a 'Data_in' subfolder. SET data for dashboard import must be placed in a 'Data_in' folder in the current working directory."
    )
    )
  } else {
  # Look for SET pin data file
  filepath_pin <- Sys.glob(file.path(here::here("Data_in"), "*PinData*")) 
  shiny::req(!is.null(filepath_pin))
  if(length(filepath_pin) == 0) {
    showModal(modalDialog(
      title = "No SET pin data",
      "Could not find SET pin data in the 'Data_in' folder. SET pin data file name must include the words 'PinData'"
    )
    )
  }
  
  # Look for SET station data file
  filepath_station <- Sys.glob(file.path(here::here("Data_in"), "*StationData*")) 
  shiny::req(!is.null(filepath_station))
    if(length(filepath_station) == 0) {
    showModal(modalDialog(
      title = "No SET station data",
      "Could not find SET station data in the 'Data_in' folder. Station data file name must include the words 'StationData'"
    )
    )
    }
  }
  shiny::req(length(filepath_pin) > 0, length(filepath_station) > 0)
  
  withProgress(message = "Just a moment", value = 0, {
    
    incProgress(1/3, detail = "...importing and formatting data")
    
    # Combine SET data in a single file
    unlink(list.files(path = here::here(), pattern = "^dataMaid"))
    temp_pin <- read.csv(filepath_pin, fileEncoding="UTF-8-BOM") # need to add fileEncoding argument so doesn't add junk characters to first column name
    temp_station <- read.csv(filepath_station, fileEncoding="UTF-8-BOM")
    
    factor_cols <- c("datum", "double_read_type", "dpl_label", "network_code", "observation_type", "park_code", "park_name", "pin_collection", "pin_flag_code", "pin_label", "protected_status", "SET_instrument", "SET_reader", "SET_recorder", "site_name", "station_code", "station_name", "station_status", "validation_name", "validation_status")
    integer_cols <- c("SET_offset_mm", "pin_length_mm", "pin_height_mm", "standardized_soil_elev_mm", "soil_elev_m") # 
    
    temp_pin %<>% 
      dplyr::mutate(
        QAQC_COMMENTS = NA, # add a notes column for user to edit in dashboard
        record_ID = row_number()) %>%
      dplyr::select(QAQC_COMMENTS, record_ID, everything()) %>% # arrange column order
      dplyr::mutate_at(vars(matches(factor_cols)), as.factor) %>% # for easier filtering
      dplyr::mutate_at(vars(matches(integer_cols)), as.integer) %>%
      dplyr::mutate_at(vars(matches("_date")), lubridate::as_date, format = "%Y-%m-%d")
      temp_pin$QAQC_COMMENTS <- as.character(temp_pin$QAQC_COMMENTS)

    temp_pin2 <- FuncBreakDates(dat = temp_pin)
    
    temp_station2 <- temp_station %>%
      dplyr::mutate_at(c("network_code", "park_name", "park_code", "site_name", "station_name", "station_code", "station_status", "protected_status"), as.factor) %>%
      dplyr::mutate_at(vars(matches("_date")), lubridate::as_date, format = "%Y-%m-%d") 
    
    rv$DataSET <- as.data.frame(FuncCalcChange(dat = temp_pin2)) # <<<<<<<<<<<<<<<<<< NEED THIS TO BE FASTER. TRY COLLAPSE::SETTRANSFORM, MAYBE ALSO SELECT ONLY NECESSARY COLS
    rv$DataStation <- temp_station2
    
    shiny::req(!is.null(rv$DataSET))

    incProgress(2/3, detail = "...saving formatted data")
    showModal( # Pop-up modal asking user to enter prefix to append to saved files
      modalDialog(
        textInput("out_prefix", "Prefix to append to output files: ",
                  placeholder = paste0("SET_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date()))),
                value = paste0("SET_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date())))
      ),
      footer = tagList(
        actionButton("button_goSave", "SAVE")
      )
    ))
  
  observeEvent(input$button_goSave, {
   
    if(!dir.exists(file.path(here::here(), "Data_out"))) {
      dir.create(file.path(here::here(), "Data_out"))} # create a 'Data_out' subfolder if it doesn't exist
    saveRDS(isolate(reactiveValuesToList(rv)), here::here("Data_out", paste0(input$out_prefix, ".RDS")))
    
    write_csv(rv$DataSET, here::here("Data_out", paste0(input$out_prefix, ".csv")))
    
    Sys.sleep(0.25)
    showModal(modalDialog(
      title = "Done",
      HTML("The data for dashboard use have been saved as '", input$out_prefix, ".RDS' in the folder 'Data_out' of the current working directory, ", getwd(), ".The corresponding .csv file has been saved in the same location. <br><br>You may now navigate to the EXAMINE DATA tab to run Data Check reports.") 
    ))
  })
        
    })
}, ignoreInit = TRUE)

# (Home) Load data as RDS ----
observeEvent(eventExpr = input$button_LoadRDS, {
  showModal(modalDialog(
    fileInput("saved_data_file", label = "Import a SET file already formatted for dashboard use ('RDS' extension)", placeholder = "Click 'Browse...' button then navigate to file", accept = c('.RDS'), width = "100%"),
    footer = tagList(
      modalButton("Cancel")
    )
  ))
})

observeEvent(eventExpr = input$saved_data_file, {
  tryCatch(out <- readRDS(input$saved_data_file$datapath),
           error = function(e) print("Cannot import the selected file"))
  if(class(out)!="list") {
    showModal(modalDialog(
    title = "Error",
    "Cannot import the selected file. Please try a different .RDS file."
    ))
    rm(out)
    }
  
  shiny::req(!is.null(out))

  for(i in c("DataSET", "DataStation")) {
    if(!is.null(out[i])) {
    rv[[i]] <- out[[i]] # load the data in the dashboard
    }
  }
  # if(!is.null(rv$DataSET)) {
  #   rv$DataSET %<>% 
  #     dplyr::mutate(
  #       visit_date = lubridate::as_date(visit_date, format = "%m/%d/%Y"),
  #       Yr = lubridate::year(visit_date), # for annual summaries
  #       visit_month = factor(lubridate::month(visit_date), levels = 1:12),
  #       Week = factor(lubridate::week(visit_date), levels = 1:53)
  #     )
  # }

  Sys.sleep(0.25)
  showModal(modalDialog(
  title = "Done",
  "You may now navigate to the EXAMINE DATA tab to run Data Check reports."
  ))
})

# (Examine) Run data check (dataMaid report) ----
observeEvent(eventExpr = input$button_RunDataCheck, {
  shiny::req(!is.null(rv))
  unlink(list.files(path = here::here(), pattern = "^dataMaid")) 
  rv$ShowDM <- FALSE
  
  if(is.null(input$out_TableSummary_rows_selected)) {
    showModal(modalDialog(
      title = "No record selected",
      "From the table, select the record for which you would like to generate a data check report"
    )
    )
  }
  shiny::req(!is.null(input$out_TableSummary_rows_selected))

  shiny::req(!is.null(rv$SubDataSET), !is.null(rv$SubDataSummary), !is.null(input$out_TableSummary_rows_selected)) 

withProgress(message = "Generating data check report...", value = 0, { # show progress bar
    
    check_sub <- rv$SubDataSET %>%
      dplyr::select(-QAQC_COMMENTS, -record_ID, -observation_type, -diff_height_mm, -diff_days, -change_per_year_mm) %>%
      dplyr::mutate(station_name = as.character(station_name),
                    visit_date = as.character(visit_date)) %>%
      dplyr::filter(station_name == rv$SubDataSummary[input$out_TableSummary_rows_selected, "station_name"])

    shiny::req(!is.null(check_sub))
    if(nrow(check_sub) > 0) {

dataMaid::makeDataReport(data = check_sub, visuals = dataMaid::setVisuals(
  character = "vertLabStandardVisual",
  factor = "vertLabStandardVisual",
  labelled = "vertLabStandardVisual",
  haven_labelled = "vertLabStandardVisual",
  numeric = "standardVisual",
  integer = "standardVisual",
  logical = "vertLabStandardVisual",
  Date = "standardVisual"), listChecks = FALSE, smartNum = FALSE, reportTitle = paste0("Station ", toupper(as.character(rv$SubDataSummary[input$out_TableSummary_rows_selected, "station_name"]))), render = TRUE, output = "html", openResult = FALSE, replace = TRUE, useVar = names(check_sub), file = "dataMaid.Rmd")
      rv$ShowDM <- file.exists(here::here("dataMaid.html"))

    }
  })

showModal(modalDialog(
  title = "Done",
  "The report can be viewed in the 'Data Check Report' tab."
  ))
})

# (Thresholds) Seasonal plots ----
renderUI({
  shiny::req(!is.null(rv$SubDataSET), !is.null(input$sel_HeatSite))

  rv$SeasonalPlots <- FuncPlotlyScatter(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite))
  Sys.sleep(1)
})

# (Thresholds) Recalculate thresholds ----
observeEvent(eventExpr = input$button_RecalcThresholds, { 

  shiny::req(!is.null(input$sel_CalcUnit), !is.null(rv$SubDataSET), !is.null(input$sel_HeatSite), !is.null(input$sel_ThresholdType))
  withProgress(message = "Just a moment...", detail = "...calculating thresholds", value = 0, {
    cat("line766")
    # Calculate threshold levels
    if(input$sel_ThresholdType == "quant") {
    shiny::req(!is.null(input$sel_CalcUnit), !is.null(input$sel_QuantileGroup), !is.null(input$sel_QuantileLower), !is.null(input$sel_QuantileUpper))
    rv$ThreshDataSET <- FuncCalcQuant(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite), sel_unit = input$sel_CalcUnit)
    }
    cat("line772")

    if(input$sel_ThresholdType == "numb") {
      shiny::req(!is.null(input$sel_CalcUnit), !is.null(input$sel_ThresholdLower), !is.null(input$sel_ThresholdUpper))
      rv$ThreshDataSET <- FuncCalcThresh(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite), sel_unit = input$sel_CalcUnit)
    }
    cat("line777")
    # Create heat plots
    shiny::req(!is.null(rv$ThreshDataSET))
    # pick_list <- rv$ThreshDataSET %>% # pick-list for user clicks on heat plot
    #   dplyr::select(station_name, SET_direction_azimuth) %>%
    #   dplyr::arrange(station_name, SET_direction_azimuth) %>%
    #   distinct()
    # pick_list$curveNumber <- 0:(nrow(pick_list)-1)
    # rv$PickList <- pick_list

    rv$ThreshHeatPlots <- FuncPlotlyHeatPlot(dat = rv$ThreshDataSET)
    cat("line788")
    # Count threshold levels
    rv$ThreshCounts <- rv$ThreshDataSET %>%
    dplyr::select(record_ID, park_code, site_name, station_name, visit_date, lower_cutoff, upper_cutoff, level) %>%
    dplyr::group_by(park_code, site_name, station_name, visit_date, lower_cutoff, upper_cutoff, level, .drop = FALSE) %>%
    dplyr::summarise(N = n()) %>%
    dplyr::mutate(hover_label = paste0("park_name: ", park_code, "<br>Station: ", station_name, "<br>Date: ", visit_date, "<br>Upper Cutoff: ", upper_cutoff, "<br>lower_cutoff", lower_cutoff, "<br>LEVEL: ", level, "<br>COUNT: ", N))
    cat("line795")
    # Create map
    shiny::req(!is.null(rv$ThreshCounts), !is.null(rv$DataStation))
    rv$MapDat <- rv$ThreshCounts %>%
      dplyr::ungroup() %>%
      dplyr::select(site_name, station_name, visit_date, lower_cutoff, upper_cutoff, level, N) %>%
      dplyr::filter(visit_date != min(rv$ThreshCounts$visit_date, na.rm = TRUE)) %>% # first survey date is all NA's so omit
      spread(key = level, value = N, drop = FALSE, fill = 0) %>%
      left_join(unique(rv$DataStation[c("park_name", "park_code", "site_name", "station_name", "station_latitude", "station_longitude")]), by = c("site_name", "station_name"))
    })

  # Sys.sleep(2)
})
```

```{r page_examine_data}

# Show/hide well panels ----
renderUI({
  if(!is.null(rv$DataSET)) {
    shinyjs::showElement("wp_ExaminePark")
    } else {
      shinyjs::hideElement("wp_ExaminePark")
    }

  if(!is.null(rv$DataSET) & !is.null(input$sel_Park)) {
    shinyjs::showElement("wp_ExamineFilter")
    } else {
      shinyjs::hideElement("wp_ExamineFilter")
    }
})

# Filter and summarize data ----
renderUI({
 
  shiny::req(!is.null(rv$DataSET), !is.null(input$sel_Park), !is.null(input$sel_YrRange[1]), !is.null(input$sel_YrRange[2]), !is.null(input$sel_ProcessLevel), !is.null(input$sel_ObservationType))

  temp_subdata <- rv$DataSET %>%
  dplyr::filter(park_name == input$sel_Park & visit_yr >= as.integer(input$sel_YrRange[1]) & visit_yr <= as.integer(input$sel_YrRange[2]) & dpl_label %in% input$sel_ProcessLevel & observation_type %in% input$sel_ObservationType) 

  shiny::req(!is.null(temp_subdata))
  shiny::req(nrow(temp_subdata) > 0)

  temp_summary <- temp_subdata %>%
    dplyr::group_by(park_name, site_name, station_name) %>%
    dplyr::summarize(
      MinYr = as.integer(min(visit_yr, na.rm = TRUE)),
      MaxYr = as.integer(max(visit_yr, na.rm = TRUE)),
      TotalSurveyYrs = n_distinct(visit_yr),
      NumRecords = n(),
      Raw_perc = round(100* sum(dpl_label == "Raw")/NumRecords),
      Provisional_perc = round(100* sum(dpl_label == "Provisional")/NumRecords),
      Accepted_perc = round(100* sum(dpl_label == "Accepted")/NumRecords)
      ) %>% 
    dplyr::ungroup() %>%
    droplevels()

  temp_summary <- droplevels(temp_summary)
  shiny::req(!is.null(temp_summary))
  shiny::req(nrow(temp_summary) > 0)
  
  temp_date_summary <- temp_subdata %>%
    dplyr::group_by(park_name, site_name, station_name, visit_date) %>%
    dplyr::summarize(
      NumRecords = n(),
      Raw_perc = round(100* sum(dpl_label == "Raw")/NumRecords),
      Provisional_perc = round(100* sum(dpl_label == "Provisional")/NumRecords),
      Accepted_perc = round(100* sum(dpl_label == "Accepted")/NumRecords)
      ) %>%
    dplyr::ungroup() %>%
    droplevels()
    
  shiny::req(!is.null(temp_summary))
  shiny::req(nrow(temp_summary) > 0)

  rv$SubDataSET <- as.data.frame(temp_subdata)
  rv$SubDataSummary <- as.data.frame(temp_summary)
  rv$SubDataDateSummary <- as.data.frame(temp_date_summary)
  
  Sys.sleep(0.25) # ADD THIS SLEEP TIME, OR WILL GENERATE ERROR WHEN ADVANCE TO NEXT PAGE (TOO QUICKLY?)
  })

# Update QAQC_COMMENTS column ----
observeEvent(input$out_TableRaw_cell_edit, {
  FuncUpdateCheckCols(input_edit = input$out_TableRaw_cell_edit, output_table = rv$SubDataSETRaw, proxyDT = raw_proxyDT)
  })

# Export data records with QAQC_COMMENTS ----
output$button_exportQAQC_COMMENTS <- downloadHandler(
    filename = function() {
      return(paste0("SET_commented_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date())),".csv"))
      },
    content = function(file) {
      write_csv(rv$SubDataSETRaw %>% dplyr::filter(!is.na(QAQC_COMMENTS)), file)
    }
    )

# Table of selected station ----
renderUI({
  shiny::req(!is.null(rv$SubDataSET), !is.null(rv$SubDataSummary))
  if(!is.null(input$out_TableSummary_rows_selected)) {

  rv$SubDataSETRaw <- rv$SubDataSET %>%
    dplyr::mutate(station_name = as.character(station_name)) %>%
    dplyr::filter(station_name ==  rv$SubDataSummary[input$out_TableSummary_rows_selected, "station_name"]) %>% # user-selected station
    dplyr::select(-visit_yr, -visit_month, -visit_week, -diff_height_mm, -diff_days, -change_per_year_mm)
  }
  Sys.sleep(0.25) # Need to give it time to update, or will generate warning on dashboard
})
```

```{r page_threshold_plots}

# Show/hide well panels ----
renderUI({
  if(!is.null(rv$SubDataSET)) {
    shinyjs::showElement("wp_Thresholds")
    } else {
      shinyjs::hideElement("wp_Thresholds")
    }
})
```

```{r page_export_NERRs}
renderUI({
  if(!is.null(rv$DataSET)) {
    shinyjs::showElement("wp_NERRs")
    } else {
      shinyjs::hideElement("wp_NERRs")
    }
})

renderUI({
  shiny::req(!is.null(input$sel_ExportParks), !is.null(rv$DataSET))
  rv$DataSET_NERRs <- FuncFormatSET_NERRs(dat = rv$DataSET)
  Sys.sleep(0.25) # Need to give it time to update, or will generate warning on dashboard
})

output$button_exportNERRs <- downloadHandler(
    filename = function() {
      return(paste0("SET_forNERRs_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date())),".csv"))
      },
    content = function(file) {
      write_csv(rv$DataSET_NERRs, file)
    }
    )
```
    
HOME
=========================================

Column {data-width=5}
-------------------------------------

Column {data-width=30}
-------------------------------------

```{r image1, echo = FALSE}
htmltools::img(src="images/Jim_SET2.jpg", width = "100%", style="display: block; margin-top:10px; margin-bottom:0px; margin-right:40px; margin-left:-20px")
```

```{r image2, echo = FALSE}
htmltools::img(src="images/Assateague.jpg", width = "100%", style="display: block; margin-top:10px; margin-bottom:0px; margin-right:40px; margin-left:-20px")
```

Column {data-width=5}
-------------------------------------

Column {data-width=60}
-------------------------------------
#### <font size="5"> Monitoring Wetland Elevation Dynamics in National park_name Units</font> 

<font size="4"> 
This dashboard is an interactive tool for QAQC and visualizing wetland elevation data collected in national park units. Wetland elevation is monitored using the Surface Elevation Table (SET) and marker horizons. Summary tables and graphs can be exported as .csv and .png files, respectively.</font>

#### <font size="4">**Quick-Start Instructions**</font>

<font size="4">1.  Place .csv data files in the 'Data_in' folder. Every data file must have one of these text strings in the file name: 'Marker Data.csv', 'SET Data.csv', or 'Station Data.csv'.</font>

<font size="4">2.  Click the green 'Import Data... (from CSV or SQL)' button at the bottom of this page.</font>

<font size="4">3.  Navigate to the other dashboard pages to view summary tables, graphs, and maps of the data.</font>

```{r}
actionButton("button_LoadRDS", "Load an Existing RDS File",
             style="color:black; background-color: lightgreen; border:2px; margin:5px; width:230px; display:inline-block;")

actionButton("button_ImportCSV", "Import from CSV Files",
             style="color:black; background-color: lightgreen; border:2px; margin:5px; width:200px; display:inline-block;")

actionButton("button_ImportSQL", "Import from SQL", style="color:black; background-color: lightgreen; border:2px; margin:5px; width:200px; display:inline-block;")
```

Column {data-width=10}
-------------------------------------

Examine Data
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_examine}  
shinyjs::hidden( # hide this well panel until !is.null(rv$DataSET)
  wellPanel(
    id = "wp_ExaminePark",
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      selectInput(
        "sel_Park",
        label = "Select a park_name: ",
        choices = sort(unique(rv$DataSET$park_name)),
        selected = switch(is.null(input$sel_Park)+1, input$sel_Park, sort(unique(rv$DataSET$park_name))[1])
        )
      }),
    
    em("Select a record to run a data check report and view the raw data"),
    
    br(), 
    
    br(),
    
    downloadLink("button_exportQAQC_COMMENTS", label = "Export COMMENTED data records"),
    
    br(),
    
    br(),

    actionButton("button_RunDataCheck", "Run Data Check", width = "100%", style="border-color:black; background-color: lightgreen; border:0px; margin:0px")
  )
)

shinyjs::hidden( # hide this well panel until !is.null(input$sel_Park)
  wellPanel(
    id = "wp_ExamineFilter",
    
    renderUI({
      shiny::req(!is.null(rv$DataSET), !is.null(input$sel_Park))
      # saveRDS(isolate(reactiveValuesToList(input)), paste0("temp_input.RDS"))
      # saveRDS(isolate(reactiveValuesToList(rv)), paste0("temp_rv.RDS"))<<<
      sliderInput(
        "sel_YrRange",
        label = "Range of years to summarize:", 
        min = min(rv$DataSET$visit_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), 
        max = max(rv$DataSET$visit_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), 
        step = 1, 
        sep="", 
        value = c(min(rv$DataSET$visit_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), max(rv$DataSET$visit_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE)), 
        dragRange = TRUE, 
        width = "85%")
      }),
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      checkboxGroupInput(
        "sel_ProcessLevel",
        label = "Include these data processing levels: ",
          choices = sort(unique(rv$DataSET$dpl_label)),
        selected = switch(is.null(input$sel_ProcessLevel)+1, input$sel_ProcessLevel, sort(unique(rv$DataSET$dpl_label)))
        )
      }),
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      checkboxGroupInput(
        "sel_ObservationType",
        label = "Include these observation types: ",
        choices = sort(unique(rv$DataSET$observation_type)),
        selected = switch(is.null(input$sel_ObservationType)+1, input$sel_ObservationType, sort(unique(rv$DataSET$observation_type)))
        )
      })
  )
)
```

Examine Data - Outputs {data-width=100 .tabset .tabset-fade}
-------------------------------------
  
### Year Range and Total Years of Data

```{r examine_summary}
output$out_TableSummary <- DT::renderDT({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)

  DT::datatable(
    rv$SubDataSummary,
    filter = "top",
    rownames = FALSE,
    selection = list(mode = "single", target = "row"), # extract information on user-selected rows
    options = list(
      columnDefs = list(list(className = "dt-center", targets = "_all"))))
})

DTOutput("out_TableSummary")
tags$style("#out_TableSummary{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```

### Data Check Report
```{r data_check_report}

addResourcePath("working_dir", here::here())

renderUI({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)
  shiny::req(rv$ShowDM == TRUE)
  tags$iframe(src="working_dir/dataMaid.html", width = "100%", height = "100%", overflow = "scroll") # don't use 100% for height because it won't show the whole thing
})
```

### Selected Raw Data
```{r selected_raw_data}
output$out_TableRaw = DT::renderDT({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)
  shiny::req(!is.null(rv$SubDataSETRaw))

  temp_raw <- DT::datatable(
    rv$SubDataSETRaw,
    escape = FALSE,
    filter = "top",
    rownames = FALSE,
    selection = "none",
    editable = list(target = "cell", disable = list(columns = c(1:ncol(rv$SubDataSETRaw)))), 
    options = list(
      autoWidth = TRUE,
      columnDefs = list(
        list(className = "dt-center", targets = "_all"),
        list(width = '200px', targets = 0)
        )
      )
  )
  
  temp_raw %>% formatStyle("QAQC_COMMENTS", backgroundColor = "yellow")
})

raw_proxyDT <- DT::dataTableProxy("out_TableRaw")
dataTableOutput("out_TableRaw")
tags$style("#out_TableRaw{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```

Threshold Plots
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_heat} 
    
renderUI({
      shiny::req(!is.null(rv$SubDataSET))
      selectInput(
        "sel_HeatSite",
        label = "Select a Site: ",
        choices = sort(unique(rv$SubDataSET$site_name)),
        selected = switch(is.null(input$sel_HeatSite)+1, input$sel_HeatSite,
                          sort(unique(rv$SubDateSET$site_name))[1])
        )
      })

shinyjs::hidden( # hide this well panel until !is.null(rv$SubDataSET)
  wellPanel(
    id = "wp_Thresholds",
    
    renderUI({
      shiny::req(!is.null(rv$SubDataSET))
      radioButtons("sel_CalcUnit",
                   label = "Measurement unit:",
                   choiceNames = list("Change(mm) per year", "Change(mm) from prior"),
                   choiceValues = list("change_per_year_mm", "diff_height_mm"),
                   selected = "change_per_year_mm")
      }),
      
    
    renderUI({
      shiny::req(!is.null(rv$SubDataSET))
      radioButtons("sel_ThresholdType",
                   label = "Set thresholds as:",
                   choiceNames = list("Numbers", "Quantiles"),
                   choiceValues = list("numb", "quant"),
                   selected = "numb")
      }),
    
    renderUI({
  shiny::req(!is.null(input$sel_ThresholdType))
  conditionalPanel(
    condition = "(input.sel_ThresholdType == 'quant')",
    numericInput("sel_QuantileLower",
                 label = "Enter lower quantile (or 0 for no lower limit)",
                 value = 0.1,
                 min = 0.0,
                 max = 1.0,
                 step = 0.05),
    numericInput("sel_QuantileUpper",
                 label = "Enter upper quantile (or 1 for no upper limit)",
                 value = 0.9,
                 min = 0.0,
                 max = 1.0,
                 step = 0.05),
    
    radioButtons("sel_QuantileGroup",
               label = "Calculate quantiles:",
               choiceNames = list("by site", "by station"),
               choiceValues = list("site", "station"),
               selected = "site")
    )
  }),
  
  
  renderUI({
  shiny::req(!is.null(input$sel_ThresholdType))
  conditionalPanel(
    condition = "(input.sel_ThresholdType == 'numb')",
    numericInput("sel_ThresholdLower",
                 label = "Enter lower limit",
                 value = -20),
    numericInput("sel_ThresholdUpper",
                 label = "Enter upper limit",
                 value = 20)
    )
  })
  ))

br()

actionButton("button_RecalcThresholds", "Recalculate Thresholds", style="border-color:black; background-color: lightgreen; width:230px; border:0px; margin:0px")

hr()

renderUI({
  shiny::req(!is.null(rv$MapDat))
  
  map_zoom <- min(RgoogleMaps::MaxZoom(lonrange = range(rv$MapDat$station_longitude, na.rm = TRUE), latrange = range(rv$MapDat$station_latitude, na.rm = TRUE)))
  
  sliderInput("sel_MapZoom", label = "Set map zoom (smaller = wider view):", min = map_zoom - 3, max = 20, value = map_zoom - 1, step = 0.5, ticks = FALSE, dragRange = FALSE, width = "95%")
})

renderUI({
  shiny::req(!is.null(rv$MapDat))
  
  sliderInput("sel_MapPieSize", label = "Resize map pie charts:", min = 10, max = 100, value = 60, step = 10, ticks = FALSE, dragRange = FALSE, width = "95%")
})
```

Threshold Plots - Output {.tabset .tabset-fade}
-------------------------------------

### Heat Plots
####
```{r heat}
# Addressed the unequal widths issue but putting legend in same R chunk as the graph
renderPlot({
  shiny::req(!is.null(rv$ThreshDataSET), !is.null(rv$ThreshHeatPlots), !is.null(input$sel_CalcUnit))
  
  discrete_cols <- c("#ffd700", "#add8e6", "#ffa500")
  names(discrete_cols) <- c("below", "between(inclusive)", "above")
  
  # hacky legend because plotly heatmaps can't generate horizontal colorbars
  heat_legend <- grid.arrange(ggpubr::as_ggplot(
    get_legend(
      ggplot(rv$ThreshDataSET, aes(x = visit_date, y = pin_position, fill = level)) +
        geom_tile() + 
        scale_fill_manual(values = discrete_cols, na.translate = FALSE, drop = FALSE, name = switch((input$sel_CalcUnit == "change_per_year_mm")+1, "Threshold Category (CHANGE SINCE PRIOR):   ", "Threshold Category (CHANGE PER YEAR):  ")) + 
        theme(legend.position = "top",
              legend.key.width = unit(1, "cm"),
              legend.text = element_text(size = 16, margin = margin(r = 2, unit = "cm")),
              legend.title = element_text(size = 16)
        )
      )
    )
  )
  }, height = 60)
 
renderPlotly({ # separate validation statements so they are checked in sequence
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  rv$ThreshHeatPlots
})
```

### Pie Charts

```{r pie_charts}
# Initially tried renderPlotly, but had problems when percentiles were not initially selected, then later selected
  
output$out_PieCharts <- renderPlotly({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  shiny::req(!is.null(rv$ThreshCounts))
  FuncPlotlyPieMatrix(dat = rv$ThreshCounts)
})

tags$style("#out_PieCharts{height:100vh;overflow-x:scroll;overflow-y:scroll}")
plotlyOutput('out_PieCharts', height="100%", width = "100%")
```

### Map

```{r thresh_map}
output$out_ThreshMap <- renderLeaflet({
  
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  
  shiny::req(!is.null(rv$MapDat), !is.null(input$sel_MapZoom), !is.null(input$sel_MapPieSize)) # !is.null(rv$UnitPoly), 
  
  discrete_cols = c("#ffd700", "#add8e6", "#ffa500")
  discrete_levels = c("below", "between(inclusive)", "above")
  
  long_vec <- na.exclude(rv$MapDat$station_longitude)
  lat_vec <- na.exclude(rv$MapDat$station_latitude)
  map_center <- c(mean(c(min(long_vec), max(long_vec))), mean(c(min(lat_vec), max(lat_vec))))
  
  thresh_map <- leaflet() %>%
    addProviderTiles("Esri.WorldImagery", options = providerTileOptions(noWrap = TRUE)) %>%
    # addPolygons(data = rv$UnitPoly[rv$UnitPoly@data$UNIT_CODE == unique(rv$MapDat$park_code),], layerId = rv$UnitPoly@data$UNIT_CODE, stroke = TRUE, color = "white", weight = 1, opacity = 1, fillOpacity = 0) %>% # park unit outline
    addScaleBar() %>% 
    addMinicharts(
      lng = rv$MapDat$station_longitude,
      lat = rv$MapDat$station_latitude,
      time = rv$MapDat$visit_date,
      type = "pie",
      transitionTime = 0,
      layerId = rv$MapDat$station_name, # doesn't work with a label field
      height = input$sel_MapPieSize,
      width = input$sel_MapPieSize,
      chartdata = as.matrix(subset(rv$MapDat, select = discrete_levels)),
      colorPalette = discrete_cols) %>%
    setView(lng = map_center[1], lat = map_center[2], zoom = input$sel_MapZoom)

  thresh_map
  })

tags$style("#out_ThreshMap {height: calc(100vh - 100px) !important;}")
leafletOutput('out_ThreshMap', height="100%", width = "100%")
```

### Seasonal Patterns

```{r seasonal}
output$out_SeasonalPlots <- renderPlotly({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  shiny::req(!is.null(rv$SeasonalPlots))
  rv$SeasonalPlots
  })

tags$style("#out_SeasonalPlots{height:100vh;overflow-y:scroll}") # Y-axis scrollbar if overflows
plotlyOutput('out_SeasonalPlots', height="100%", width = "100%")
```

Export Data for NERRs
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_NERRs}  
renderUI({
  shiny::req(!is.null(rv$DataSET))
  checkboxGroupInput("sel_ExportParks",
    label = "Include data for these Parks: ",
    choices = sort(unique(rv$DataSET$park_code)),
    selected = sort(unique(rv$DataSET$park_code))
    )
  })
    
downloadLink("button_exportNERRs", label = "Export SET data for NERRs")
```

Data for NERRs - Outputs
-------------------------------------
  
### Data Formatted for NERRs

```{r NERRs}

output$out_NERRs <- DT::renderDT({
  FuncOrderCheck(import = TRUE, examine = FALSE, plot = FALSE)
  shiny::req(!is.null(rv$DataSET_NERRs))
  temp_NERRs <- DT::datatable(
    rv$DataSET_NERRs,
    filter = "top",
    rownames = FALSE,
    options = list(
      columnDefs = list(list(className = "dt-center", targets = "_all"))))
})

DTOutput("out_NERRs")
tags$style("#out_NERRs{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```
