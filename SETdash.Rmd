---
title: "SET Visualizer"
output:
  flexdashboard::flex_dashboard:
    theme: yeti
    orientation: columns
runtime: shiny
---

```{r global, include=FALSE}
### PICK UP FROM HERE--DOES NOT CALC THRESH FOR BISCAYNE BISC1
### FIX
# Heat plot legend should not update until recalculate thresholds button is pressed
# Speed up action when recalculate thresholds
# Quantile doesn't work for heat plot
# Change per year--really it depends on season, so instead of this show some indication of season and then have a warning sign that the time btwn events is not necessarily approx annual and that hover text will show # of days since last reading and that season of survey may influence pin height. Instead of change per year, the hover text should include # of days since last reading 
# Seasonal patterns--check what y-axis is, I think it's not change-per-yr right?
# Can i get x-axis label on each heat plot matrix?

### PICK UP FROM HERE
# Records Export Page 
# >> side panel allows user to choose which columns to view (and export). 



### NOTES
# Converted all tibbles to data frames to get rid of phantom column name errors

### QUESTIONS
# pin_position --is that column name correct?
# check if I identified the correct cols to be factor, integer, date formats
# Removing records with NA in any of these columns (station_name, event_date_UTC, SET_direction_azimuth, pin_position, pin_height_mm)--any reason to keep those in? Can provide an output of which records were excluded, or just a summary of counts
# When calculating diff, only use 'Standard observation'?
# How to deal with some pins having base pin height and others not?
# On heat map page, do you want to be able to select a park or use previously selected park and filters?
# Will a station always have 4 directions and 9 pins/dxn? (otherwise need to have flexible heat map sizing)

### TO DO
# Make sure x-axis range consistent across all stations in site

### NAMING RULES
# Functions: FuncTest(dat1_there, dat2_here)
# Action buttons: button_PushMe
# User inputs: sel_SelectMe
# Lists, data frames, vectors, variables...: station_files_list, station_df, station_vec, here_is_a_variable
# Data frame cols: df$ColThisOne, df$ColThatOne
# List elements: list$ElementOne, list$ElementTwo
# Reactive elements: rv$ThisOne, rv$ThatOne
# Temporary variables: temp_this_df
# Well panel id's: wp_FilterParkSite

rm(list=ls())

### Load libraries -----
# Will automatically install any libraries it can't find
pkgs <- c("flexdashboard", 
              "shiny", 
              "knitr", 
              "odbc", # pull data from SQL server
              "scales",
              "leaflet", 
              "RgoogleMaps", # for mapzoom
              "plotly", 
              "tidyverse", 
              "plyr", 
              "readr",
              "magrittr", 
              "leaflet.extras", 
              "lubridate", 
              "here", 
              "httr", # use web services
              "rgdal", # to use readOGR
              "sp", # transform projections
              "purrr", # for applying functions to dplyr groups
              "dataMaid", # for data checks
              "shinyFiles", # for user to save files in specified location
              "RColorBrewer", # to display brewer palettes
              "shinyjs", # for easy functions that use JavaScript
              "stringr", # to detect text snippets
              "tmaptools", # for flexible color mapping
              "reactable",
              "data.table", # for fast lag calcs
              "DT", # for interactive tables
              "zoo", # for year-month and carry-forward NA's for lag
              "cowplot", # to get legends from plots
              "gridExtra", # for arranging plots and adding plot annotations (ggplotly can't do captions or subtitles)
              "RgoogleMaps", # for MaxZoom & MinZoom
              "leaflet.minicharts") # for pie charts in leaflet maps
installed_pkgs <- pkgs %in% installed.packages()
if (length(pkgs[!installed_pkgs]) > 0) install.packages(pkgs[!installed_pkgs],dep=TRUE) 
lapply(pkgs, library, character.only = TRUE)

options(shiny.maxRequestSize = 20*1024^2, 
        timeout = 300,
        stringsAsFactors = FALSE,
        DT.options = list(
          hover = TRUE,
          scrollX = TRUE,
          scrollY = TRUE,
          autoWidth = FALSE),
        # Header width doesn't match body width when this is set to TRUE. To fix, would need to include code to recalculate widths only after a tab is visible. If setting column widths, need to set autoWidth to TRUE
        dplyr.summarise.inform = FALSE
)

# dataMaid helper function that needs to be in global - rotate plot, wrap and truncate long labels
vertLabPlot <- function(x, xlab, main) { 
  qplot(x = stringr::str_wrap(substring(x, 0, 42), 15), xlab = xlab, main = main) +
    coord_flip()
  }

# dataMaid helper function that needs to be in global - visualFunction for character, factor, labelled and logical variables
vertLabStandardVisual  <- function(v, vnam, doEval = TRUE) {
  v <- dataMaid:::escapeRStyle(na.omit(v))
  thisCall <- call("vertLabPlot", x=v, xlab="", main=vnam)
  if (doEval) {
    return(eval(thisCall))
  } else return(deparse(thisCall))
}
```

```{r startup}

rv <- reactiveValues(DataSET = NULL, DataStation = NULL, DataEvent = NULL, UnitPoly = NULL, SubDataSET = NULL, SubDataSummary = NULL, SubDataDateSummary = NULL, PlotData = NULL, ShowDM = FALSE, ThreshDataSET = NULL, ThreshCounts = NULL, PickList = NULL, ThreshHeatPlots = NULL, SeasonalPlots = NULL, MapDat = NULL, DataSET_NERRs = NULL)

thresh3_cols = c("#ffd700", "#add8e6", "#ffa500")
thresh3_levels = c("big decline", "within expected range", "big increase")

# cbp1 <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#0072B2", "#D55E00", "#999999", "#F0E442", "#000000", "chocolate4", "purple4", "chartreuse", "lightpink", "honeydew2") # Colorblind-friendly palette that will be used throughout
```

```{r css}

# This allows renderTables to scroll when overflow
tags$style(".chart-wrapper {
  overflow-x:scroll;
  overflow-y:scroll;
}")

tags$style("table.dataTable tbody th, table.dataTable tbody td input.form-control {
    padding: 2px 5px; 
}") # reduce padding in data tables
```

```{r functions}

### FUNCTIONS ----

## Reactable Functions
# Reactable bar chart function 
bar_chart <- function(label, width = "100%", height = "14px", fill = "#00bfc4", background = NULL) {
  bar <- div(style = list(background = fill, width = width, height = height))
  chart <- div(style = list(flexGrow = 1, marginLeft = "6px", background = background), bar)
  div(style = list(display = "flex", alignItems = "center"), label, chart)
}

# Reactable tooltip formatting
with_tooltip <- function(value, tooltip) {
  tags$abbr(style = "text-decoration: underline; text-decoration-style: dotted; cursor: help", title = tooltip, value)
}

## Other Functions
FuncAllNoneButtons <- function(cond, name_all, name_none) {
  # Function to create 'Select All' and 'Select None' action buttons
  #
  # Args:
  #   cond:  The input ID that needs to be defined for buttons to show (enter as input.XXX rather than as input$XXX)
  #   name_all:  ID to assign to 'Select All' button
  #   name_none:  ID to assign to 'Select None' button
  #
  conditionalPanel(
    condition = paste0("typeof ", cond, " !== 'undefined'"),
    actionButton(name_all, "Select All", style="color:black; display:inline-block; border:1px; padding:4px 12px;"),
    actionButton(name_none, "Select None", style="color:black; display:inline-block; border:1px; padding:4px 12px;")
  )
}

FuncParkBoundaries <- function(park_vec) {
  # Function to get park unit boundaries from IRMA
  #
  # Args:
  #   park_vec: Vector of 4-letter park codes for which boundaries should be obtained
  #
  # Returns:
  #   A data frame with additional columns classifying survey date by week, month, year
  
     unitBoundaryURL <- paste0("https://services1.arcgis.com/fBc8EJBxQRMcHlei/ArcGIS/rest/services/IMD_Units_Generic_areas_of_analysis_(AOAs)_-_IMD_BND_ALL_UNITS_AOA_nad_py_view/FeatureServer/1/query?where=UNITCODE+%3D+%27, park_vec, %27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=") # save output as WGS84

     if(httr::http_status(GET(unitBoundaryURL))$category!="Success") { # if not a valid service call or if the web service is down, abort
       showModal(
         urlModal(unitBoundaryURL, title = "Data Retrieval Error", subtitle = paste0("Error retrieving park_name unit boundary data from IRMA. The message from the web service is: `", http_status(GET(unitBoundaryURL))$message, "`.\n\nTo confirm this is a problem with the web service (and not the dashboard), enter the above URL in a browser and see if data successfully downloads. If an error results, email IRMA support (irma@nps.gov) for assistance."))
       )
       }

     shiny::req(httr::http_status(GET(unitBoundaryURL))$category=="Success")

    tempUnitOutput <- "tempUnit.geojson"
    download.file(unitBoundaryURL, tempUnitOutput) # readOGR geoJSON driver needs dsn to be a local file, so download the file first, then read it

    imported_dat <- tryCatch(rgdal::readOGR(dsn = tempUnitOutput, dropNULLGeometries = FALSE), error=function(e) print("Error retrieving data")) # return error message if problems still arise with downloading from web services
    if(class(imported_dat)!="SpatialPolygonsDataFrame") {
       showModal(
         urlModal(unitBoundaryURL, title = "Data Retrieval Error", subtitle = paste0("Could not successfully retrieve park_name unit boundary data from IRMA. To see if this is a problem with the web service (and not the dashboard), enter the above URL in a browser and see if data successfully downloads with boundary information in geojson format. If necessary, email IRMA support (irma@nps.gov) for assistance."))
       )
    }

    shiny::req(class(imported_dat)=="SpatialPolygonsDataFrame")
    imported_dat <- sp::spTransform(imported_dat, sp::CRS("+proj=longlat +datum=WGS84")) # convert to WGS84

    rv$UnitPoly <- imported_dat
    rm(imported_dat)
    unlink("tempUnit.geojson")
}

FuncCalcChange <- function(dat) {
  # Function to calculate change per year for pin height
  #
  # Args:
  #   dat:  A final pin data frame
  #
  # Returns:
  #   A data frame with an additional column calculating change in pin height since last survey event. When prior survey is NA, will give NA.
  #
  # dat$temp_event_date_UTC <- dat$event_date_UTC # need this to calculate DIffDays correctly (skipping the NA dates, but still need event_date_UTC to order the readings correctly)
  # dat$temp_event_date_UTC[is.na(dat$pin_height_mm)] <- NA
  
  
  dt1 <- dat %>%
    dplyr::filter(observation_type == "Standard") %>%
    dplyr::select(record_ID, park_code, station_name, SET_direction_azimuth, pin_position, event_date_UTC, pin_height_mm) %>%
    dplyr::arrange(event_date_UTC)
  
  dt2 = data.table(dt1 %>% dplyr::select(-record_ID))
  dt2[, c("event_date_UTC_lag", "pin_height_mm_lag") := shift(.SD, 1), by=c("park_code", "station_name", "SET_direction_azimuth", "pin_position")]
  dt3 <- dplyr::bind_cols(dt1["record_ID"], as.data.frame(dt2)) %>%
    dplyr::select(record_ID, event_date_UTC_lag, pin_height_mm_lag) %>%
    dplyr::right_join(dat, by = "record_ID") %>%
      dplyr::mutate(
        diff_height_mm = pin_height_mm - pin_height_mm_lag,
        diff_days = event_date_UTC - event_date_UTC_lag) %>%
    dplyr::select(-event_date_UTC_lag, -pin_height_mm_lag) %>%
    dplyr::ungroup()
  
  return(dt3)
}
  
FuncCalcQuant <- function(dat) {
  # Function to classify diff_height_mm by user-specified groups and quantiles
  #
  # Args:
  #   dat:  A filtered SET data frame for the selected site
  #
  # Returns:
  #   A data frame with an additional columns classifying diff_height_mm relative to specified quantiles per group
  #
  dat <- droplevels(dat)

  dat %<>% dplyr::mutate(
    GroupingVar = switch(input$sel_QuantileGroup,
                         "site" = site_name,
                         "station" = station_name)) 
  quant_list <- dat %>%
    dplyr::group_by(GroupingVar) %>%
  group_map(~ quantile(.x$diff_height_mm, probs = c(input$sel_QuantileLower, input$sel_QuantileUpper), na.rm = TRUE))
  quant_df <- data.frame(do.call("rbind", quant_list))
  names(quant_df) <- c("lower_cutoff", "upper_cutoff")
  quant_df$GroupingVar <- levels(dat$GroupingVar)
  
  dat2 <- dat %>%
    dplyr::left_join(quant_df, by = "GroupingVar")
  dat2$level <- ifelse(
      dat2$diff_height_mm < dat2$lower_cutoff, "big decline", ifelse(
      dat2$diff_height_mm > dat2$upper_cutoff, "big increase", "within expected range"))
  dat2$GroupingVar <- NULL
  dat2$level <- factor(dat2$level, levels = c("big decline", "within expected range", "big increase"))

  return(dat2)
  }

FuncCalcThresh <- function(dat) {
  # Function to classify diff_height_mm by user-specified numeric thresholds
  #
  # Args:
  #   dat:  A filtered SET data frame for the specified site
  #
  # Returns:
  #   A data frame with an additional column classifying diff_height_mm relative to specified thresholds
  #
  dat <- droplevels(dat)
  dat2 <- dat
  dat2$lower_cutoff <- input$sel_ThresholdLower
  dat2$upper_cutoff <- input$sel_ThresholdUpper
  dat2$level <- ifelse(
      dat2$diff_height_mm < dat2$lower_cutoff, "big decline", ifelse(
      dat2$diff_height_mm > dat2$upper_cutoff, "big increase", "within expected range"))
  
  dat2$level <- factor(dat2$level, levels = c("big decline", "within expected range", "big increase"))
  return(dat2)
}
  
FuncPlotlyScatter <- function(dat, x_nam = "Wk", trans_y = "identity", add_loess = TRUE, rotate_x = FALSE) {
  # Function to generate scatterplot of data
  #
  # Args:
  #   dat:  A data frame with the raw data
  #   x_nam: Column name for x-axis variable
  #   trans_y: Transformation to apply to y axis
  #   add_loess:  Add loess smooth? (will be biased by censored data)
  #   rotate_x: should x-axis labels be rotated?
  #
  # Returns:
  #   List of scatterplot
  # 
  
  shiny::req(sum(!is.na(dat$pin_height_mm)) > 0) # make sure there are data
  
  if(x_nam == "event_date_UTC") {
    xaxes_min = min(dat$event_date_UTC, na.rm = TRUE)
    xaxes_max = max(dat$event_date_UTC, na.rm = TRUE)
  }
  
  yaxes_min = min(dat$pin_height_mm, na.rm = TRUE)
  yaxes_max = max(dat$pin_height_mm, na.rm = TRUE)
  
  # Create the plot(s)
    
    p_points <- ggplot(data = dat, aes(x = event_date_wk, y = pin_height_mm, text = paste0("Site: ", site_name, "<br>Station: ", station_name, "<br>Visit Date: ", event_date_UTC, "<br>X-value: ", event_date_wk, "<br>Y-value: ", pin_height_mm))) +
      geom_jitter(aes(fill = event_date_yr, color = event_date_yr), size = 2, alpha = 0.5, show.legend = c(fill = TRUE, color = FALSE, shape = FALSE))
  
    # Create a pretty x-axis
    if(x_nam == "event_date_UTC") {
      p1_points <- p_points + scale_x_date(date_breaks = "1 year", date_labels = "%Y", limits = c(xaxes_min, xaxes_max))
    } else {
      p1_points <- p_points + scale_x_discrete(breaks = levels(dat$event_date_wk), drop = FALSE)
    }
    
    # If adding loess smooth...
    # if(add_loess) {
      p1_points <- p1_points + geom_smooth(data = dat, aes(x = event_date_wk, y = pin_height_mm), method = "loess", size = 0.5, alpha = 0.2, show.legend = FALSE)
      # }
    
    # Final formatting of plots
    p1_points <- p1_points +
      scale_y_continuous(trans = trans_y, labels = function(x) as.character(round(x,1)), breaks = pretty_breaks(), limits = c(yaxes_min, yaxes_max)) + # alternatively, can use 'coord_cartesian(ylim = c(axes_min, axes_max))' to zoom in to the limits rather than "cutting off" the limits, as setting limits within scale_y_continuous() would do 
      theme_bw(base_size = 11) +
      {if(rotate_x) {theme(axis.text.x = element_text(angle = 60, hjust = 1))}} +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.position = "top",
            legend.text = element_text(size = 16),
            legend.title = element_text(size = 16)) +
      facet_wrap(. ~ station_name, drop = TRUE, ncol = 1) # add the name as facet label
    out_plotly <- ggplotly(
      p1_points,
      height = 400*length(unique(dat$station_name))) # THIS IS NOT WORKING--CAN'T SCROLL DOWN
    
  return(out_plotly)
}

FuncPlotlyHeatPlot <- function(dat, discrete_cols = thresh3_cols, discrete_levels = thresh3_levels) {
  # Function to create plotly heatmaps of diff_height_mm, organized station. Using plot_ly because ggplotly is too slow for interactive heat plots b/c it doesn't recognize the input as a heatmap and creates a scatterplot where each rectangle is drawn separately with all the necessary attributes. 
  #
  # Args:
  #   dat:  A filtered SET data frame with quantile/threshold classification for a single site
  #   discrete_cols: For discrete fill, the vector of colors
  #   discrete_levels: For discrete fill, the levels corresponding with colors
  #   
  # Returns:
  #   GGplot heat map
  #
  dat2 <- dat %>%
    ungroup() %>%
    dplyr::select(record_ID, site_name, station_name, SET_direction_azimuth, pin_position, event_date_UTC, pin_height_mm, observation_type, pin_position, diff_height_mm, diff_days, lower_cutoff, upper_cutoff, level) %>%
    dplyr::arrange(record_ID) %>%
    dplyr::mutate(hover_label = paste0("Record ID: ", record_ID, "<br>Visit Date: ", event_date_UTC, "<br>Observation Type: ", observation_type, "<br>Pin Position: ", pin_position, "<br>Pin Height (mm): ", pin_height_mm, "<br>Height Diff (mm): ", diff_height_mm, "<br>Days Diff: ", diff_days, "<br>Upper Cutoff: ", upper_cutoff, "<br>Lower Cutoff", lower_cutoff, "<br>LEVEL: ", level)) %>%
    droplevels()
  
  # Calculate total and relative heights
  temp_distinct <- dat2 %>% 
    dplyr::select(station_name, SET_direction_azimuth, pin_position) %>%
    distinct()
  total_page_ht <- 30*nrow(temp_distinct)
  rel_hts <- (temp_distinct %>% dplyr::count(station_name) %>% pull(n))/nrow(temp_distinct)
  
  heat_station_list <- vector("list", length = length(unique(dat2$station_name))) # each list element is a station
  
 heat_station_list <- lapply(sort(unique(dat2$station_name)), function(i) {
    cat("i = ", i)
    # Data for this station
    subdat <- dplyr::filter(dat2, station_name == i) %>%
      droplevels()

    # Pipe directions for this station
    pipe_dxn_list <- vector("list", length = length(unique(subdat$SET_direction_azimuth)))
    pipe_dxn_list <- lapply(sort(unique(subdat$SET_direction_azimuth)), function(j) { # subplot the pipe directions for a station
      cat("j = ", j, " // ")
      subdat_pipe <- dplyr::filter(subdat, SET_direction_azimuth == j)
  
    # create number matrix to put values in the heatmap cells
    template <- subdat_pipe %>%
      dplyr::select(pin_position, event_date_UTC) %>%
      expand(pin_position, event_date_UTC) %>%
      left_join(subdat_pipe[c("SET_direction_azimuth", "pin_position", "event_date_UTC", "diff_height_mm", "hover_label", "level")], by = c("pin_position", "event_date_UTC")) %>%
      dplyr::arrange(event_date_UTC, pin_position)
    txt <- matrix(pull(template, "diff_height_mm"), nrow=length(unique(template$pin_position)))
    txt[is.na(txt)] <- " " # convert NA to blank, otherwise it will show as "new text"

        
        # Create discrete color scale
  use_cols <- discrete_cols[which(discrete_levels %in% unique(na.omit(template$level)))]
  
  if(length(use_cols) > 0) {
    temp_seq <- seq(0,1, length.out = length(use_cols)+1)
  rep_seq <- rep(temp_seq[c(-1, -length(temp_seq))], each = 2)
  z = c(temp_seq[1], rep_seq, temp_seq[length(temp_seq)])
  color_scale <- data.frame(z=z,col=rep(use_cols, each = 2)) # the default color for NA is white
  } else {
    color_scale <- data.frame(z = c(0, 1), col = rep("#ffd700", 2))
  }
  
  
    plot_ly(
      data = template, 
      # source = "heatmap",
      text = text,
      width = 52*length(unique(template$event_date_UTC)), 
      height = total_page_ht, # can't specify heights in subplot, need to set it at this plot_ly level
      showscale = FALSE) %>%
      plotly::add_heatmap(
        x = ~as.factor(event_date_UTC),
        y = ~as.integer(pin_position),
        text = ~hover_label, # hover information
        hoverinfo ="text",
        z = ~as.numeric(factor(template$level, ordered = T, levels = discrete_levels)), # assign discrete colors to the cells
        colorscale = color_scale, 
        xgap = 0.5, # spacing between heatmap cells
        ygap = 0.5
        ) %>% 
      layout(
        hoverlabel = list(align = "left"),
        xaxis = list( # x-axis
          title = "Survey Date",
          tickangle = 270,
          titlefont=list(size=16, family = "Arial")),
        yaxis = list( # y-axis
          autorange = "reversed",
          dtick = 1)
        ) %>%
      add_annotations( 
        x = template$event_date_UTC,
        y = as.integer(template$pin_position),
        align = "center",
        text = txt, # add the values in the cells 
        showarrow = FALSE) %>%
      add_annotations( # Pipe Direction subtitle
        text = paste0("Pipe Direction ", unique(template$SET_direction_azimuth)),
        xref = "paper",
        yref = "paper",
        x = 0.5,
        y = 1.02,
        xanchor = "center",
        yanchor = "bottom", # y anchor uses 'middle', x anchor uses 'center'
        showarrow = FALSE,
        font=list(size=16, family = "Arial")
        )
    })
    
    plotly::subplot(
        pipe_dxn_list,
        nrows = length(pipe_dxn_list),
        shareX = TRUE,
        shareY = FALSE,
        titleX = TRUE,
        titleY = FALSE
        ) %>%
        add_annotations( # shared y-axis title
          x = -0.05,
          y = 0.55,
          text = "Pin Position",
          showarrow = F, 
          xref="paper",
          yref="paper",
          xanchor="right",
          yanchor="middle", # y anchor uses 'middle', x anchor uses 'center'
          textangle=-90,
          font=list(size=16, family = "Arial")) %>%
      add_annotations( # Station name as title
        x = 0.01,
        y = 1.02,
        text = paste0("STATION ", i), 
        showarrow = F, 
        xref="paper",
        yref="paper",
        xanchor="left",
        yanchor="bottom",
        font=list(size=20, family = "Arial")
        ) %>%
      layout(
          margin = list(
          t=50,
          b=15,
          l= 80,
          r=40)
        )
 }) 
 
 final_heat_plotly <- # put the station plots together
   plotly::subplot(
     heat_station_list,
     nrows = length(heat_station_list),
     shareX = FALSE,
     shareY = FALSE,
     titleX = TRUE,
     titleY = FALSE,
     heights = rel_hts,
     which_layout = 1)
 
  return(final_heat_plotly)
}

FuncPlotlyPieMatrix <- function(dat, discrete_cols = thresh3_cols, discrete_levels = thresh3_levels, plot_title) {
  # Function to create plotly pie chart matrix of pin_height_diff, organized by user-selected grouping. 
  #
  # Args:
  #   dat:  A filtered SET data frame with quantile/threshold classification for a single site
  #   discrete_cols: For discrete fill, the vector of colors
  #   discrete_levels: For discrete fill, the levels corresponding with colors
  #   plot_title: Title for plot page
  #   
  # Returns:
  #   Page of plotly pie charts
  #
  
  fig <- plot_ly()
  m <- list(
    l = 300,
    r = 90,
    b = 100,
    t = 100,
    pad = 0
  )
  
  stations_vec <- sort(unique(dat$station_name))
  date_vec <- sort(unique(dat$event_date_UTC))
  
  for(s in 1:length(stations_vec)) {
    station <- stations_vec[s]
    for(d in 2:length(date_vec)) { # first date is always NA's for change in pin height
      survey_date <- date_vec[d]
      fig <- fig %>% 
        
        add_pie(data = dplyr::filter(dat, station_name == station & event_date_UTC == survey_date),
                name = paste0(station, "_", survey_date),
                labels = ~level, 
                values = ~N,
                textposition = 'inside',
                textinfo = 'label+percent',
                insidetextfont = list(color = '#FFFFFF'),
                hoverinfo = 'text',
                text = ~hover_label,
                marker = list(colors = discrete_cols, line = list(color = '#FFFFFF', width = 1)),
                domain = list(row = s-1, column = d-1))
      }
  }
  
  width_px <- 80 * length(date_vec) # this is the plot width (paper)
  height_px <- 200 + (80 * length(stations_vec)) # this is the plot height (paper)

  date_seq_px <- seq(40, width_px-40, by = 80)/width_px # this is where date labels should align on x-axis, when reference is "paper"
  y_seq_px <- seq(40, height_px-40, length.out = length(stations_vec))/height_px
  title_loc <- 1 + (90/height_px) #it's into the top margin space, when reference is "container"
  legend_loc <- 1 + (50/height_px)
  dates_loc_bottom <- -1 * (50/height_px)
  
  dates_labels_bottom <- list(
  text = as.list(as.character(date_vec)),
  xref = "paper",
  yref = "container",
  yanchor = "center",
  xanchor = "center",
  font =list(size = 14),
  align = "right",
  x = date_seq_px,
  y = dates_loc_bottom,
  showarrow = FALSE)
  
  station_labels_left <- list(
    text = as.list(sort(unique(dat$station_name), decreasing = TRUE)),
    xref = "paper",
    yref = "paper",
    xanchor = "right",
    yanchor = "center",
    font =list(size = 14),
    align = "center",
    x = -0.02,
    y = y_seq_px,
    showarrow = FALSE)
  
  fig_final <- fig %>% layout(
    margin = m,
    title = list(
      text = plot_title,
      x = 0.5,
      y = title_loc,
      xref = "container", # gets cut off if referenced to the plot only ("paper")
      yref = "paper",
      xanchor = "center",
      yanchor = "center"),
    showlegend = TRUE,
    legend = list(
      orientation = "h",
      x = 0.5,
      xref = "container",
      yref = "paper",
      xanchor = "center",
      y = legend_loc,
      yanchor = "center"),
    grid=list(
      rows=length(stations_vec),
      columns=length(date_vec)),
    width = width_px,
    height = height_px,
    autosize = FALSE,
    annotations = station_labels_left) 
  
  fig_final <- fig_final %>% layout(annotations = dates_labels_bottom)
  
  
  
  
  
  fig <- fig %>% layout(
    title = "Pie Charts (each row is a Station, each column is a Survey Event)", 
    showlegend = FALSE,
    grid=list(
      rows=length(unique(dat$station_name)),
      columns=length(unique(dat$event_date_UTC))),
    xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    autosize = FALSE,
    width = 80 * length(unique(dat$event_date_UTC)), # this is the plot width (paper)
    height = 2 * length(unique(dat$station_name)) # this is the plot height (paper)
    )
  
  return(fig)
}

FuncOrderCheck <- function(import = TRUE, examine = TRUE, plot = TRUE) {
  # Function to check if data have been imported, filtered, and plot data summarized

  if(import == TRUE) {
    shiny::validate(
      need(!is.null(rv$DataSET), message = "No data available. Please first import SET data (green buttons on 'Home' tab)."))
  }
  
  if(examine == TRUE) {
    shiny::req(!is.null(rv$DataSET))
    shiny::validate(
      need(!is.null(rv$SubDataSET), message = "Please first use the 'Big Picture Summary' tab to choose a subset of data to examine."))
    shiny::validate(
      need(!is.null(rv$SubDataSummary), message = "Please first use the 'Big Picture Summary' tab to choose a subset of data to examine."))
  }
  
  if(plot == TRUE) {
    shiny::req(!is.null(rv$SubDataSET))
    shiny::validate(
      need(!is.null(rv$ThreshDataSET), message = "Please first enter thresholds criteria for the heat plots, then click the green 'Recalculate Thresholds' button"))
    shiny::validate(
      need(!is.null(rv$ThreshHeatPlots), message = "Please first enter thresholds criteria for the heat plots, then click the green 'Recalculate Thresholds' button"))
  }
}

FuncFormatSET_NERRs <- function(dat) {
  temp_NERRs <- dat %>%
    dplyr::filter(park_code %in% input$sel_export_parks) %>%
    dplyr::mutate(
      reserve = park_code,
      set_id = paste0(station_name, "_Pipe", SET_direction_azimuth),
      year = lubridate::year(event_date_UTC),
      month = lubridate::month(event_date_UTC),
      day = lubridate::day(event_date_UTC),
      arm_position = SET_direction_azimuth,
      arm_qaqc_code = NA,
      pin_number = paste0("pin_", pin_position),
      height_mm = pin_height_mm,
      qaqc_code = NA) %>%
    dplyr::select(reserve, set_id, year, month, day, arm_position, arm_qaqc_code, pin_number, height_mm, qaqc_code)
  return(temp_NERRs)
}
  
```

```{r action_buttons}

# Generic action to cancel modal ----
observeEvent(eventExpr = input$button_CancelModal, {
  removeModal()
  })

# (Home) Import and format data via SQL database download ----
observeEvent(eventExpr = input$button_ImportSQL, {
  shiny::validate(need(!is.null(input$database_driver), message = "Enter a valid SQL Driver"))
  shiny::validate(need(!is.null(input$database_server), message = "Enter a valid database server"))
  
  withProgress(message = "Just a moment", value = 0, {
    
    incProgress(2/12, detail = "...connecting to SQL server")
        
         # Build a new connection and connect to the database server
        
        con <- DBI::dbConnect(odbc::odbc(),
                      Driver =  "SQL Server", #input$database_driver,
                      Server = "INP2300SQL01\\NTWK", #input$database_server,
                      Trusted_Connection = "Yes")
  dbGetQuery(con, "USE [SET]")
  
  incProgress(3/12, detail = "...getting Marker Horizon data")
  
  marker_horizon_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_marker_horizon_data')
  # shiny::validate(need(!is.null(marker_horizon_data), message = "Could not import Marker Horizon data"))
  
  incProgress(4/12, detail = "...getting Pin Group data")
  
  pin_group_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_SET_pin_information')
  # shiny::validate(need(!is.null(pin_group_data), message = "Could not import Pin Groups data"))
  
  incProgress(5/12, detail = "...getting Pin data")
  
  pin_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_SET_data_FINAL')
  # shiny::validate(need(!is.null(pin_data), message = "Could not import Pin data"))
  
  incProgress(6/12, detail = "...getting Station data")
  
  station_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_stations')
  # shiny::validate(need(!is.null(station_data), message = "Could not import Station data"))
  
  incProgress(7/12, detail = "...getting Events data")
  
  event_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_events')
  # shiny::validate(need(!is.null(event_data), message = "Could not import Event data"))
  
  incProgress(8/12, detail = "...getting CriticalInformation data")
  critical_information_data <- dbGetQuery(con, 'SELECT * FROM ssrs.vw_dbx_critical_information')
  
  # Disconnect from the database server to free up resources
  dbDisconnect(con)
      # } else {
      #   renderText({"You did not input a database server"})
      # }
  
    # }) # end of SQL connect

    # Save SQL files as .csv 
  incProgress(9/12, detail = "...formatting and saving data files")
  
  # Class types for data columns
      factor_cols <- c("datum", "location_datum", "double_read_type", "dpl", "network_code", "network_name", "observation_type", "park_code", "park_name", "pin_collection", "pin_flag_code", "protected_status", "SET_instrument", "SET_reader", "SET_recorder", "site_name", "station_code", "station_name", "station_status", "validation_name", "validation_status", "exclude_int_user", "exclude_cumul_user", "reader_name", "core_type", "core_condition", "foot_present", "group_isretired", "marker_horizon_data_collected", "pin_data_collected", "double_read_pin_collected", "category_code", "category_label") # these variables have a relatively small set number of possible values
    integer_cols <- c("SET_direction_azimuth", "SET_offset_mm", "pin_length_mm", "station_elev_m", "pin_height_mm", "standardized_soil_elev_mm", "soil_elev_m", "exclude_int_user_ID", "exclude_int_reason_ID", "exclude_cumul_user_ID", "exclude_cumul_reason_ID", "inundation_level_cm", "core_measurement_number", "core_measurement_depth_mm", "pin_position") 
  
  if(!dir.exists(file.path(here::here(), "Data_in"))) {
    dir.create(file.path(here::here(), "Data_in"))} # create a 'Data_in' subfolder if it doesn't exist
  
    dat_list <- list()
    dat_vec <- c("marker_horizon_data", "pin_group_data", "pin_data", "station_data", "event_data", "critical_information_data")
    
    # Look for data .csv files. This double-checks the data have been saved to computer
    
  for(x in dat_vec) {
    # shiny::validate(need(!is.null(get(x)), message = paste0("Cannot find ", x, " data. Please check for SQL import problems.")))
    
    write.csv(get(x), file = here::here("Data_in", paste0(x, ".csv")), row.names = FALSE)
    
    filepath_string<- Sys.glob(file.path(here::here("Data_in",  paste0(x, ".csv"))))
    temp_dat <- read.csv(filepath_string, na.strings = "NULL", fileEncoding="UTF-8-BOM") # need to add fileEncoding argument so doesn't add junk characters to first column name
    temp_dat[temp_dat == "NA"] <- NA # weird issue where read.csv converts cells to character "NA" instead of empty string NA
    
    # Data frame-specific additional formatting
    if(x == "pin_data") {
      temp_dat %<>% dplyr::rename(dpl = dpl_label) %>% 
      dplyr::arrange(network_name, park_name, site_name, station_name, SET_direction_azimuth, pin_position, event_date_UTC, observation_type) %>%
      dplyr::mutate(record_ID = row_number()) %>%
      dplyr::select(record_ID, everything()) # arrange column order
    }
    
    if(x == "event_data") {
      temp_dat %<>% dplyr::rename(dpl = DPL)
    }
      
    # General formatting for all
    temp_dat %<>%
      dplyr::mutate_at(vars(matches(factor_cols)), as.factor) %>% 
      dplyr::mutate_at(vars(matches(integer_cols)), as.integer) %>%
      dplyr::mutate_at(vars(matches("_date")), lubridate::as_date, format = "%Y-%m-%d")
    
    if("event_date_UTC" %in% names(temp_dat)) {
      temp_dat %<>%
        dplyr::mutate(
          event_date_yr = lubridate::year(event_date_UTC), # for annual summaries
          event_date_mnth = factor(lubridate::month(event_date_UTC), levels = 1:12),
          event_date_wk = factor(lubridate::week(event_date_UTC), levels = 1:53)
          )
    }
    dat_list[[x]] <- temp_dat
  }
    
    # Clear things out
    rm(list = dat_vec)
    unlink(list.files(path = here::here(), pattern = "^dataMaid"))
    
    rv$DataSET <- as.data.frame(FuncCalcChange(dat = dat_list$pin_data)) # <<<<<<<<<<<<<<<<<< NEED THIS TO BE FASTER. TRY COLLAPSE::SETTRANSFORM, MAYBE ALSO SELECT ONLY NECESSARY COLS
    rv$DataStation <- dat_list$station_data
    
    shiny::req(!is.null(rv$DataSET))

    incProgress(11/12, detail = "...saving formatted data")
    showModal( # Pop-up modal asking user to enter prefix to append to saved files
      modalDialog(
        textInput("out_prefix", "Prefix to append to output files: ",
                  placeholder = paste0("SET_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date()))),
                value = paste0("SET_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date())))
      ),
      footer = tagList(
        actionButton("button_go_save", "SAVE")
      )
    ))
    
    observeEvent(input$button_go_save, {
   
    if(!dir.exists(file.path(here::here(), "Data_out"))) {
      dir.create(file.path(here::here(), "Data_out"))} # create a 'Data_out' subfolder if it doesn't exist
    saveRDS(isolate(reactiveValuesToList(rv)), here::here("Data_out", paste0(input$out_prefix, ".RDS")))
    
    write_csv(rv$DataSET, here::here("Data_out", paste0(input$out_prefix, "_formatted.csv")))
    
    Sys.sleep(0.5)
    showModal(modalDialog(
      title = "Done",
      HTML("The formatted data have been saved as '", input$out_prefix, ".RDS' (for dashboard use) and as '", input$out_prefix, "_formatted.csv' (to view in Excel, if you wish) in the 'Data_out' folder of the current working directory, ", getwd(), ". The original (raw) tables imported from SQL have been saved as .csv files in the 'Data_in' folder of the current working directory. <br><br>You may now navigate to the BIG PICTURE SUMMARY tab to run Data Check reports.") 
    ))
    
  }) # end of save
    }) # end of progress messages
  }) # end of SQL import

# (Home) Load data as RDS ----
observeEvent(eventExpr = input$button_LoadRDS, {
  showModal(modalDialog(
    fileInput("saved_data_file", label = "Import a SET file already formatted for dashboard use ('RDS' extension)", placeholder = "Click 'Browse...' button then navigate to file", accept = c('.RDS'), width = "100%"),
    footer = tagList(
      modalButton("Cancel")
    )
  ))
})

observeEvent(eventExpr = input$saved_data_file, {
  tryCatch(out <- readRDS(input$saved_data_file$datapath),
           error = function(e) print("Cannot import the selected file"))
  if(class(out)!="list") {
    showModal(modalDialog(
    title = "Error",
    "Cannot import the selected file. Please try a different .RDS file."
    ))
    rm(out)
    }
  
  shiny::req(!is.null(out))
  unlink(list.files(path = here::here(), pattern = "^dataMaid"))

  for(i in c("DataSET", "DataStation")) {
    if(!is.null(out[i])) {
    rv[[i]] <- out[[i]] # load the data in the dashboard
    }
  }

  Sys.sleep(0.5)
  showModal(modalDialog(
  title = "Done",
  "You may now navigate to the BIG PICTURE SUMMARY tab to run Data Check reports."
  ))
})

# (Examine) Run data check (dataMaid report) ----
observeEvent(eventExpr = input$button_RunDataCheck, {
  shiny::req(!is.null(rv))
  unlink(list.files(path = here::here(), pattern = "^dataMaid")) 
  rv$ShowDM <- FALSE
  
      cat("line777")
        # saveRDS(isolate(reactiveValuesToList(input)), paste0("temp_input.RDS"))
  # saveRDS(isolate(reactiveValuesToList(rv)), paste0("temp_rv.RDS"))

  shiny::req(!is.null(rv$SubDataSET), !is.null(rv$SubDataSummary)) 

withProgress(message = "Generating data check report...", value = 0, { # show progress bar
    
    check_sub <- rv$SubDataSET %>%
      dplyr::select(-record_ID, -pin_flag_notes, -vegetation_notes, -SET_direction_notes, -SET_notes, -dpl_note) 
    # %>%
    #   dplyr::mutate(station_name = as.character(station_name),
    #                 event_date_UTC = as.character(event_date_UTC))

    shiny::req(!is.null(check_sub))
    if(nrow(check_sub) > 0) {

dataMaid::makeDataReport(data = check_sub, visuals = dataMaid::setVisuals(
  character = "vertLabStandardVisual",
  factor = "vertLabStandardVisual",
  labelled = "vertLabStandardVisual",
  haven_labelled = "vertLabStandardVisual",
  numeric = "standardVisual",
  integer = "standardVisual",
  logical = "vertLabStandardVisual",
  Date = "standardVisual"), listChecks = FALSE, smartNum = FALSE, reportTitle = paste0("Station ", toupper(as.character(rv$SubDataSummary[input$out_TableSummary_rows_selected, "station_name"]))), render = TRUE, output = "html", openResult = FALSE, replace = TRUE, useVar = names(check_sub), file = "dataMaid.Rmd")
      rv$ShowDM <- file.exists(here::here("dataMaid.html"))

    }
  })

showModal(modalDialog(
  title = "Done",
  "The report can be viewed in the 'Data Check Report' tab."
  ))
})

# (Thresholds) Seasonal plots ----
renderUI({
  shiny::req(!is.null(rv$SubDataSET), !is.null(input$sel_HeatSite))

  rv$SeasonalPlots <- FuncPlotlyScatter(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite))
  Sys.sleep(1)
})

# (Thresholds) Recalculate thresholds ----
observeEvent(eventExpr = input$button_RecalcThresholds, { 

  shiny::req(!is.null(rv$SubDataSET), !is.null(input$sel_HeatSite), !is.null(input$sel_ThresholdType))
  withProgress(message = "Just a moment...", detail = "...calculating thresholds", value = 0, {
    cat("line766")
    # Calculate threshold levels
    if(input$sel_ThresholdType == "quant") {
    shiny::req(!is.null(input$sel_QuantileGroup), !is.null(input$sel_QuantileLower), !is.null(input$sel_QuantileUpper))
    rv$ThreshDataSET <- FuncCalcQuant(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite))
    }
    cat("line772")

    if(input$sel_ThresholdType == "numb") {
      shiny::req(!is.null(input$sel_ThresholdLower), !is.null(input$sel_ThresholdUpper))
      rv$ThreshDataSET <- FuncCalcThresh(dat = dplyr::filter(rv$SubDataSET, site_name == input$sel_HeatSite))
    }
    # Create heat plots
    shiny::req(!is.null(rv$ThreshDataSET))

    rv$ThreshHeatPlots <- FuncPlotlyHeatPlot(dat = rv$ThreshDataSET)
    cat("line788")
    # Count threshold levels
    rv$ThreshCounts <- rv$ThreshDataSET %>%
    dplyr::select(record_ID, park_code, site_name, station_name, event_date_UTC, lower_cutoff, upper_cutoff, level) %>%
    dplyr::group_by(park_code, site_name, station_name, event_date_UTC, lower_cutoff, upper_cutoff, level, .drop = FALSE) %>%
    dplyr::summarise(N = n()) %>%
    dplyr::mutate(hover_label = paste0("park_name: ", park_code, "<br>Station: ", station_name, "<br>Date: ", event_date_UTC, "<br>Upper Cutoff: ", upper_cutoff, "<br>lower_cutoff", lower_cutoff, "<br>LEVEL: ", level, "<br>COUNT: ", N))
    cat("line795")
    # Create map
    shiny::req(!is.null(rv$ThreshCounts), !is.null(rv$DataStation))
    rv$MapDat <- rv$ThreshCounts %>%
      dplyr::ungroup() %>%
      dplyr::select(site_name, station_name, event_date_UTC, lower_cutoff, upper_cutoff, level, N) %>%
      dplyr::filter(event_date_UTC != min(rv$ThreshCounts$event_date_UTC, na.rm = TRUE)) %>% # first survey date is all NA's so omit
      spread(key = level, value = N, drop = FALSE, fill = 0) %>%
      left_join(unique(rv$DataStation[c("park_name", "park_code", "site_name", "station_name", "station_latitude", "station_longitude")]), by = c("site_name", "station_name"))
    })

  # Sys.sleep(2)
})
```

```{r page_examine_data}

# Show/hide well panels ----
renderUI({
  if(!is.null(rv$DataSET)) {
    shinyjs::showElement("wp_ExaminePark")
    } else {
      shinyjs::hideElement("wp_ExaminePark")
    }

  if(!is.null(rv$DataSET) & !is.null(input$sel_Park)) {
    shinyjs::showElement("wp_ExamineFilter")
    } else {
      shinyjs::hideElement("wp_ExamineFilter")
    }
})

# Filter and summarize data ----
renderUI({
 
  shiny::req(!is.null(rv$DataSET), !is.null(input$sel_Park), !is.null(input$sel_YrRange[1]), !is.null(input$sel_YrRange[2]), !is.null(input$sel_ProcessLevel), !is.null(input$sel_ObservationType))

  rv$SubDataSET <- rv$DataSET %>%
  dplyr::filter(
    park_name == input$sel_Park & event_date_yr >= as.integer(input$sel_YrRange[1]) & event_date_yr <= as.integer(input$sel_YrRange[2]) & (dpl %in% input$sel_ProcessLevel) & (observation_type %in% input$sel_ObservationType)) %>%
    as.data.frame() 
  

  shiny::req(!is.null(rv$SubDataSET))
  shiny::req(nrow(rv$SubDataSET) > 0)

  rv$SubDataSummary <- rv$SubDataSET %>%
    dplyr::group_by(park_name, site_name, station_name) %>%
    dplyr::summarize(
      min_yr = as.integer(min(event_date_yr, na.rm = TRUE)),
      max_yr = as.integer(max(event_date_yr, na.rm = TRUE)),
      total_survey_yrs = n_distinct(event_date_yr),
      num_records = n(),
      raw_perc = round(100* sum(dpl == "Raw")/num_records),
      provisional_perc = round(100* sum(dpl == "Provisional")/num_records),
      accepted_perc = round(100* sum(dpl == "Accepted")/num_records)
      ) %>% 
    dplyr::ungroup() %>%
    droplevels() %>%
    as.data.frame()

  shiny::req(!is.null(rv$SubDataSummary))
  shiny::req(nrow(rv$SubDataSummary) > 0)
  
  rv$SubDataDateSummary <- rv$SubDataSET %>%
    dplyr::group_by(park_name, site_name, station_name, event_date_UTC) %>%
    dplyr::summarize(
      SET_reader = unique(SET_reader),
      SET_instrument = unique(SET_instrument),
      pin_collection = unique(pin_collection),
      num_records = n(),
      raw_perc = round(100* sum(dpl == "Raw")/num_records),
      provisional_perc = round(100* sum(dpl == "Provisional")/num_records),
      accepted_perc = round(100* sum(dpl == "Accepted")/num_records)
      ) %>%
    dplyr::ungroup() %>%
    droplevels() %>%
    as.data.frame()
    
      saveRDS(isolate(reactiveValuesToList(rv)), here::here("TEMP_rv.RDS"))
  shiny::req(!is.null(rv$SubDataDateSummary))
  shiny::req(nrow(rv$SubDataDateSummary) > 0)
  
  Sys.sleep(0.5) # ADD THIS SLEEP TIME, OR WILL GENERATE ERROR WHEN ADVANCE TO NEXT PAGE (TOO QUICKLY?)
  })
```

```{r page_threshold_plots}

# Show/hide well panels ----
renderUI({
  if(!is.null(rv$SubDataSET)) {
    shinyjs::showElement("wp_Thresholds")
    } else {
      shinyjs::hideElement("wp_Thresholds")
    }
})
```

```{r page_export_NERRs}
renderUI({
  if(!is.null(rv$DataSET)) {
    shinyjs::showElement("wp_NERRs")
    } else {
      shinyjs::hideElement("wp_NERRs")
    }
})

renderUI({
  shiny::req(!is.null(input$sel_export_parks), !is.null(rv$DataSET))
  rv$DataSET_NERRs <- FuncFormatSET_NERRs(dat = rv$DataSET)
  Sys.sleep(0.5) # Need to give it time to update, or will generate warning on dashboard
})

output$button_exportNERRs <- downloadHandler(
    filename = function() {
      return(paste0("SET_forNERRs_", paste0(gsub(pattern = "-", replacement = "", x = Sys.Date())),".csv"))
      },
    content = function(file) {
      write_csv(rv$DataSET_NERRs, file)
    }
    )
```
    
HOME
=========================================

Column {data-width=5}
-------------------------------------

Column {data-width=30}
-------------------------------------

```{r image1, echo = FALSE}
htmltools::img(src="images/Jim_SET2.jpg", width = "100%", style="display: block; margin-top:10px; margin-bottom:0px; margin-right:40px; margin-left:-20px")
```

```{r image2, echo = FALSE}
htmltools::img(src="images/Assateague.jpg", width = "100%", style="display: block; margin-top:10px; margin-bottom:0px; margin-right:40px; margin-left:-20px")
```

Column {data-width=5}
-------------------------------------

Column {data-width=80}
-------------------------------------
#### <font size="4"><b> Monitoring Wetland Elevation Dynamics in National Park Units</b></font> 

<font size="3"> 
This dashboard is an interactive tool for QAQC and visualizing wetland elevation data collected in national park units. Wetland elevation is monitored using the Surface Elevation Table (SET) and marker horizons. Summary tables and graphs can be exported as .csv and .png files, respectively.</font>

<font size="3"><b>IMPORT DATA - OPTION 1: PULL FROM SQL</b>

This option will generate .CSV FILES OF THE SQL VIEWS and also an .RDS FILE to run the dashboard.

1.  Enter your SQL DRIVER and DATABASE SERVER information.

```{r}
textInput("database_driver", "Enter your SQL DRIVER: ",
                  placeholder = "e.g., SQL Server",
                  value = "SQL Server"
                  )

textInput("database_server", "Enter the DATABASE SERVER: ",
                  placeholder = "e.g., INP2300SQL01\\NTWK",
                  value = "INP2300SQL01\\NTWK"
                  )
```

2.  Make sure you are on VPN. Then click the green 'Import/Summarize Data from SQL' button.

```{r}
actionButton("button_ImportSQL", "Import/Summarize Data from SQL (MUST BE ON VPN!!)", style="color:black; background-color: lightgreen; border:2px; margin:5px; width:400px; display:inline-block;")
```

3.  When the import is complete, a pop-up window will tell you where a dashboard .RDS file and .csv files of the SQL views have been saved on your computer. You may now navigate to other dashboard tabs to view raw data and QAQC summaries.
</font>

<br>

<font size="3"><b>IMPORT DATA - OPTION 2: IMPORT AN .RDS FILE</b>

Use this option if you already have an .RDS FILE to run the dashboard.

1.  Click the green 'Import/Summarize Data from RDS File' button.

```{r}
actionButton("button_LoadRDS", "Import/Summarize Data from RDS File",
             style="color:black; background-color: lightgreen; border:2px; margin:5px; width:400px; display:inline-block;")
```

2.  A pop-up screen will ask you to browse to the .RDS file you want to import. Browse to the .RDS file and double-click it or highlight the file and then select 'Open'.

3.  When the import is complete, a pop-up window will indicate you may navigate to other dashboard tabs to view raw data and QAQC summaries.
</font>

Column {data-width=10}
-------------------------------------

Big Picture Summary
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_examine}  
shinyjs::hidden( # hide this well panel until !is.null(rv$DataSET)
  wellPanel(
    id = "wp_ExaminePark",
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      selectInput(
        "sel_Park",
        label = "Select a Park: ",
        choices = sort(unique(rv$DataSET$park_name)),
        selected = switch(is.null(input$sel_Park)+1, input$sel_Park, sort(unique(rv$DataSET$park_name))[1])
        )
      }),

    actionButton("button_RunDataCheck", "Run Data Check", width = "100%", style="border-color:black; background-color: lightgreen; border:0px; margin:0px")
  )
)

shinyjs::hidden( # hide this well panel until !is.null(input$sel_Park)
  wellPanel(
    id = "wp_ExamineFilter",
    
    renderUI({
      shiny::req(!is.null(rv$DataSET), !is.null(input$sel_Park))
      sliderInput(
        "sel_YrRange",
        label = "Range of years to summarize:", 
        min = min(rv$DataSET$event_date_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), 
        max = max(rv$DataSET$event_date_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), 
        step = 1, 
        sep="", 
        value = c(min(rv$DataSET$event_date_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE), max(rv$DataSET$event_date_yr[rv$DataSET$park_name == input$sel_Park], na.rm = TRUE)), 
        dragRange = TRUE, 
        width = "85%")
      }),
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      checkboxGroupInput(
        "sel_ProcessLevel",
        label = "Include these data processing levels: ",
          choices = sort(unique(rv$DataSET$dpl)),
        selected = switch(is.null(input$sel_ProcessLevel)+1, input$sel_ProcessLevel, sort(unique(rv$DataSET$dpl)))
        )
      }),
    
    renderUI({
      shiny::req(!is.null(rv$DataSET))
      checkboxGroupInput(
        "sel_ObservationType",
        label = "Include these observation types: ",
        choices = sort(unique(rv$DataSET$observation_type)),
        selected = switch(is.null(input$sel_ObservationType)+1, input$sel_ObservationType, sort(unique(rv$DataSET$observation_type)))
        )
      })
  )
)
```

Big Picture Summary - Outputs {data-width=100 .tabset .tabset-fade}
-------------------------------------
  
### Year Range and DPL Summary

For each SET station, this table shows years in service, number of data records, and % of data in each DPL level (raw, provisional, or accepted). Click on the triangle to the left of a record to see DPL summary by survey date for that SET station.

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r}
output$out_TableSummary <- renderReactable({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)
  cat("line1239")
  
  reactable(
    rv$SubDataSummary,
    columns = list(
      park_name = colDef(name = "Park", minWidth = 160, align = "left"),
      site_name = colDef(name = "Site", minWidth = 150, align = "center"),
      station_name = colDef(name = "Station", minWidth = 150, align = "center"),
      min_yr = colDef(header = with_tooltip("First Survey", "Earliest year with survey data"), minWidth = 80, align = "center"),
      max_yr = colDef(header = with_tooltip("Recent Survey", "Most recent year with survey data"), minWidth = 80, align = "center"),
      total_survey_yrs = colDef(header = with_tooltip("# of Years", "Number of years with survey data"), minWidth = 80, align = "center"),
      num_records = colDef(name = "# of Records", minWidth = 50, align = "center"),
      raw_perc = colDef(
        header = with_tooltip("% Raw", "% of pin data records with DPL = Raw"),
        minWidth = 120,
        align = "center",
        cell = function(value) {
          width <- paste0(value, "%")
          bar_chart(value, width = width, fill = "#cc6677", background = "#e1e1e1")
          }),
      provisional_perc = colDef(
        header = with_tooltip("% Provisional", "% of pin data records with DPL = Provisional"),
        minWidth = 120,
        align = "center",
        cell = function(value) {
          width <- paste0(value, "%")
          bar_chart(value, width = width, fill = "#ddcc77", background = "#e1e1e1")
          }),
      accepted_perc = colDef(
        header = with_tooltip("% Accepted", "% of pin data records with DPL = Accepted"),
        minWidth = 120,
        align = "center",
        cell = function(value) {
          width <- paste0(value, "%")
          bar_chart(value, width = width, fill = "#6699cc", background = "#e1e1e1")
          })
      ),
    details = function(index) {
      event_info <- rv$SubDataDateSummary[rv$SubDataDateSummary$site_name == rv$SubDataSummary$site_name[index] & rv$SubDataDateSummary$station_name == rv$SubDataSummary$station_name[index], ]
      htmltools::div(style = "padding: 50px",
                     reactable(event_info, 
                               columns = list(
                                 park_name = colDef(show = FALSE),
                                 site_name = colDef(show = FALSE),
                                 station_name = colDef(show = FALSE),
                                 event_date_UTC = colDef(name = "Survey Date", minWidth = 80, align = "center"),
                                 num_records = colDef(name = "# of Records", minWidth = 50, align = "center"),
                                 raw_perc = colDef(
                                   header = with_tooltip("% Raw", "% of pin data records with DPL = Raw"),
                                   minWidth = 120,
                                   align = "center",
                                   cell = function(value) {
                                     width <- paste0(value, "%")
                                     bar_chart(value, width = width, fill = "#cc6677", background = "#e1e1e1")
                                   }),
                                 provisional_perc = colDef(
                                   header = with_tooltip("% Provisional", "% of pin data records with DPL = Provisional"),
                                   minWidth = 120,
                                   align = "center",
                                   cell = function(value) {
                                     width <- paste0(value, "%")
                                     bar_chart(value, width = width, fill = "#ddcc77", background = "#e1e1e1")
                                   }),
                               accepted_perc = colDef(
                                   header = with_tooltip("% Accepted", "% of pin data records with DPL = Accepted"),
                                   minWidth = 120,
                                   align = "center",
                                   cell = function(value) {
                                     width <- paste0(value, "%")
                                     bar_chart(value, width = width, fill = "#6699cc", background = "#e1e1e1")
                                   })
                               ),
                               defaultSorted = list(event_date_UTC = "desc"),
                               resizable = TRUE,
                               filterable = TRUE,
                               striped = FALSE,
                               highlight = TRUE,
                               showSortIcon = TRUE, 
                               compact = TRUE,
                               pagination = FALSE,
                               outlined = FALSE,
                               bordered = FALSE,
                               theme = reactableTheme(backgroundColor = "hsl(186, 56%, 94%)")
                     )
      )
    },
    resizable = TRUE, 
    filterable = TRUE,
    striped = FALSE,
    highlight = TRUE,
    showSortIcon = TRUE,
    compact = TRUE,
    bordered = TRUE,
    showPageSizeOptions = TRUE, 
    onClick = "select")
})
reactableOutput("out_TableSummary")
tags$style("#out_TableSummary{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```

### Data Check Report

```{r data_check_report}
addResourcePath("working_dir", here::here())

renderUI({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)
  shiny::validate(need(rv$ShowDM == TRUE, message = "Select a Park, then click the green 'Run Data Check' button"))

  # shiny::req(rv$ShowDM == TRUE)
  tags$iframe(src="working_dir/dataMaid.html", width = "100%", height = "100%", overflow = "scroll") # don't use 100% for height because it won't show the whole thing
})
```

### Raw Data for Selected Park

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r selected_raw_data}
  output$out_TableRaw <- renderReactable({
   
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = FALSE)
  
  reactable(
    rv$SubDataSET,
    columns = list(
      pin_flag_notes = colDef(minWidth = 180),
      vegetation_notes = colDef(minWidth = 180),
      SET_direction_notes = colDef(minWidth = 180),
      SET_notes = colDef(minWidth = 180),
      dpl_note = colDef(minWidth = 180)
      ),
    resizable = TRUE, 
    filterable = TRUE,
    striped = FALSE,
    highlight = TRUE,
    showSortIcon = TRUE,
    compact = TRUE,
    bordered = TRUE,
    showPageSizeOptions = TRUE)
})
reactableOutput("out_TableRaw")
tags$style("#out_TableRaw{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```

Change in Pin Heights
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_heat} 
    
renderUI({
      shiny::req(!is.null(rv$SubDataSET))
      selectInput(
        "sel_HeatSite",
        label = "Select a Site: ",
        choices = sort(unique(rv$SubDataSET$site_name)),
        selected = switch(is.null(input$sel_HeatSite)+1, input$sel_HeatSite,
                          sort(unique(rv$SubDateSET$site_name))[1])
        )
      })

shinyjs::hidden( # hide this well panel until !is.null(rv$SubDataSET)
  wellPanel(
    id = "wp_Thresholds",
    # 
    # renderUI({
    #   shiny::req(!is.null(rv$SubDataSET))
    #   radioButtons("sel_CalcUnit",
    #                label = "Measurement unit:",
    #                choiceNames = list("Change(mm) per year", "Change(mm) from prior"),
    #                choiceValues = list("change_per_year_mm", "diff_height_mm"),
    #                selected = "change_per_year_mm")
    #   }),
      
    
    renderUI({
      shiny::req(!is.null(rv$SubDataSET))
      radioButtons("sel_ThresholdType",
                   label = "Set thresholds as:",
                   choiceNames = list("Numbers", "Quantiles"),
                   choiceValues = list("numb", "quant"),
                   selected = "numb")
      }),
    
    renderUI({
  shiny::req(!is.null(input$sel_ThresholdType))
  conditionalPanel(
    condition = "(input.sel_ThresholdType == 'quant')",
    numericInput("sel_QuantileLower",
                 label = "Enter lower quantile (or 0 for no lower limit)",
                 value = 0.1,
                 min = 0.0,
                 max = 1.0,
                 step = 0.05),
    numericInput("sel_QuantileUpper",
                 label = "Enter upper quantile (or 1 for no upper limit)",
                 value = 0.9,
                 min = 0.0,
                 max = 1.0,
                 step = 0.05),
    
    radioButtons("sel_QuantileGroup",
               label = "Calculate quantiles:",
               choiceNames = list("by site", "by station"),
               choiceValues = list("site", "station"),
               selected = "site")
    )
  }),
  
  
  renderUI({
  shiny::req(!is.null(input$sel_ThresholdType))
  conditionalPanel(
    condition = "(input.sel_ThresholdType == 'numb')",
    numericInput("sel_ThresholdLower",
                 label = "Enter lower limit",
                 value = -20),
    numericInput("sel_ThresholdUpper",
                 label = "Enter upper limit",
                 value = 20)
    )
  })
  ))

br()

actionButton("button_RecalcThresholds", "Recalculate Thresholds", style="border-color:black; background-color: lightgreen; width:230px; border:0px; margin:0px")

hr()

renderUI({
  shiny::req(!is.null(rv$MapDat))
  
  map_zoom <- min(RgoogleMaps::MaxZoom(lonrange = range(rv$MapDat$station_longitude, na.rm = TRUE), latrange = range(rv$MapDat$station_latitude, na.rm = TRUE)))
  
  sliderInput("sel_MapZoom", label = "Set map zoom (smaller = wider view):", min = map_zoom - 3, max = 20, value = map_zoom - 1, step = 0.5, ticks = FALSE, dragRange = FALSE, width = "95%")
})

renderUI({
  shiny::req(!is.null(rv$MapDat))
  
  sliderInput("sel_MapPieSize", label = "Resize map pie charts:", min = 10, max = 100, value = 60, step = 10, ticks = FALSE, dragRange = FALSE, width = "95%")
})
```

Threshold Plots - Output {.tabset .tabset-fade}
-------------------------------------

### Heat Plots of Change

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r heat}
# Addressed the unequal widths issue by putting legend in same R chunk as the graph
renderPlot({
  shiny::req(!is.null(rv$ThreshDataSET), !is.null(rv$ThreshHeatPlots))
  
  # hacky legend because plotly heatmaps can't generate horizontal colorbars
  heat_legend <- grid.arrange(ggpubr::as_ggplot(
    get_legend(
      ggplot(rv$ThreshDataSET, aes(x = event_date_UTC, y = pin_position, fill = level)) +
        geom_tile() + 
        scale_fill_manual(values = thresh3_cols, labels = thresh3_levels, na.translate = FALSE, drop = FALSE, name = "change in Pin Height (since prior survey):   ") + 
        theme(legend.position = "top",
              legend.key.width = unit(1, "cm"),
              legend.text = element_text(size = 16, margin = margin(r = 2, unit = "cm")),
              legend.title = element_text(size = 16)
        )
      )
    )
  )
  }, height = 60)
 
renderPlotly({ # separate validation statements so they are checked in sequence
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  rv$ThreshHeatPlots
})
```

### Pie Charts of Change

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r pie_charts}
# Initially tried renderPlotly, but had problems when percentiles were not initially selected, then later selected
  
output$out_PieCharts <- renderPlotly({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  shiny::req(!is.null(rv$ThreshCounts), !is.null(input$sel_HeatSite))
  
  FuncPlotlyPieMatrix(dat = rv$ThreshCounts, plot_title = paste0(input$sel_HeatSite, ": Change in Pin Height from Prior Survey (each row is a Station, each column is a Survey Event)"))
})

tags$style("#out_PieCharts{height:100vh;overflow-x:scroll;overflow-y:scroll}")
plotlyOutput('out_PieCharts', height="100%", width = "100%")
```

### Map

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r thresh_map}
output$out_ThreshMap <- renderLeaflet({
  
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  
  shiny::req(!is.null(rv$MapDat), !is.null(input$sel_MapZoom), !is.null(input$sel_MapPieSize)) # !is.null(rv$UnitPoly), 
  
  long_vec <- na.exclude(rv$MapDat$station_longitude)
  lat_vec <- na.exclude(rv$MapDat$station_latitude)
  map_center <- c(mean(c(min(long_vec), max(long_vec))), mean(c(min(lat_vec), max(lat_vec))))
  
  thresh_map <- leaflet() %>%
    addProviderTiles("Esri.WorldImagery", options = providerTileOptions(noWrap = TRUE)) %>%
    # addPolygons(data = rv$UnitPoly[rv$UnitPoly@data$UNIT_CODE == unique(rv$MapDat$park_code),], layerId = rv$UnitPoly@data$UNIT_CODE, stroke = TRUE, color = "white", weight = 1, opacity = 1, fillOpacity = 0) %>% # park unit outline
    addScaleBar() %>% 
    addMinicharts(
      lng = rv$MapDat$station_longitude,
      lat = rv$MapDat$station_latitude,
      time = rv$MapDat$event_date_UTC,
      type = "pie",
      transitionTime = 0,
      layerId = rv$MapDat$station_name, # doesn't work with a label field
      height = input$sel_MapPieSize,
      width = input$sel_MapPieSize,
      chartdata = as.matrix(subset(rv$MapDat, select = thresh3_levels)),
      colorPalette = thresh3_cols) %>%
    setView(lng = map_center[1], lat = map_center[2], zoom = input$sel_MapZoom)

  thresh_map
  })

tags$style("#out_ThreshMap {height: calc(100vh - 100px) !important;}")
leafletOutput('out_ThreshMap', height="100%", width = "100%")
```

### Seasonal Patterns

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r seasonal}
output$out_SeasonalPlots <- renderPlotly({
  FuncOrderCheck(import = TRUE, examine = TRUE, plot = TRUE)
  shiny::req(!is.null(rv$SeasonalPlots))
  rv$SeasonalPlots
  })

tags$style("#out_SeasonalPlots{height:100vh;overflow-y:scroll}") # Y-axis scrollbar if overflows
plotlyOutput('out_SeasonalPlots', height="100%", width = "100%")
```

Export Data for NERRs
====================================== 

Inputs {.sidebar data-width=250}
-------------------------------------
```{r input_NERRs}  
renderUI({
  shiny::req(!is.null(rv$DataSET))
  checkboxGroupInput("sel_export_parks",
    label = "Include data for these Parks: ",
    choices = sort(unique(rv$DataSET$park_code)),
    selected = sort(unique(rv$DataSET$park_code))
    )
  })
    
downloadLink("button_exportNERRs", label = "Export SET data for NERRs")
```

Data for NERRs - Outputs
-------------------------------------
  
### Data Formatted for NERRs

#### <font size="3">**EXPLANATORY STUFF**</font>

* <font size="2"> Details 1</font>

* <font size="2"> Details 2</font>

```{r NERRs}

output$out_NERRs <- DT::renderDT({
  FuncOrderCheck(import = TRUE, examine = FALSE, plot = FALSE)
  shiny::req(!is.null(rv$DataSET_NERRs))
  temp_NERRs <- DT::datatable(
    rv$DataSET_NERRs,
    filter = "top",
    rownames = FALSE,
    options = list(
      columnDefs = list(list(className = "dt-center", targets = "_all"))))
})

DTOutput("out_NERRs")
tags$style("#out_NERRs{height:100vh;overflow-x:scroll;overflow-y:scroll}")
```
